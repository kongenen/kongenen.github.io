(window.webpackJsonp=window.webpackJsonp||[]).push([[189],{508:function(s,t,a){"use strict";a.r(t);var n=a(11),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h2",{attrs:{id:"目标："}},[t("a",{staticClass:"header-anchor",attrs:{href:"#目标："}},[s._v("#")]),s._v(" 目标：")]),s._v(" "),t("ul",[t("li",[s._v("我们将要学习在图像间进行特征匹配")]),s._v(" "),t("li",[s._v("使用 OpenCV 中的蛮力（Brute-Force）匹配和 FLANN 匹配")])]),s._v(" "),t("h2",{attrs:{id:"蛮力（brute-force）匹配基础"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#蛮力（brute-force）匹配基础"}},[s._v("#")]),s._v(" 蛮力（Brute-Force）匹配基础")]),s._v(" "),t("p",[s._v("蛮力匹配器很简单。首先在第一幅图像中选取一个关键点然后依次与第二幅图像的每个关键点进行（描述符）距离测试，最后返回距离最近的关键点。")]),s._v(" "),t("p",[s._v("对于BF匹配器，首先我们必须使用cv.BFMatcher()创建一个BFMatcher对象。它需要两个可选的参数，第一个是normType，它指定要使用的距离测量，默认情况下，它是cv.NORM_L2，它适用于SIFT，SURF等（cv.NORM_L1也在那里）。对于基于二进制字符串的描述符，如ORB，BRIEF，BRISK等，应使用cv.NORM_HAMMING，它使用汉明距离作为度量。如果ORB使用WTA_K==3或4，则应使用cv.NORM_HAMMING2。")]),s._v(" "),t("p",[s._v("第二个参数是布尔变量crossCheck，默认为false。如果为真，则Matcher仅返回具有值(i，j)的那些匹配，使得集合A中的第i个描述符具有集合B中的第j个描述符作为最佳匹配，反之亦然。也就是说，两组中的两个特征应该相互匹配。它提供了一致的结果，是D.Lowe在SIFT论文中提出的比率测试的一个很好的替代方案。")]),s._v(" "),t("p",[s._v("一旦创建，两个重要的方法是BFMatcher.match()和BFMatcher.knnMatch()。第一个返回最佳匹配。第二种方法返回k个最佳匹配，其中k由用户指定。当我们需要做更多的工作时，它可能是有用的。")]),s._v(" "),t("p",[s._v("就像我们使用cv.drawKeypoints()来绘制关键点一样，cv.drawMatches()帮助我们绘制匹配项。它水平堆叠两个图像，并从第一个图像到第二个图像绘制线条，显示最佳匹配。还有cv.drawMatchesKnn，它绘制了所有k个最佳匹配。如果k = 2，它将为每个关键点绘制两条匹配线。因此，如果我们想要有选择地绘制它，我们必须传递一个掩码。")]),s._v(" "),t("p",[s._v("让我们看一下每个SURF和ORB的一个例子（两者都使用不同的距离测量）。")]),s._v(" "),t("h2",{attrs:{id:"与orb描述符的强力匹配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#与orb描述符的强力匹配"}},[s._v("#")]),s._v(" 与ORB描述符的强力匹配")]),s._v(" "),t("p",[s._v("在这里，我们将看到一个关于如何匹配两个图像之间的特征的简单示例。在这种情况下，我有一个查询图像和一个目标图像。我们将尝试使用特征匹配在目标图像中查找查询图像。（图片为/samples/c/box.png和/samples/c/box_in_scene.png）")]),s._v(" "),t("p",[s._v("我们使用ORB描述符来匹配功能。所以让我们从加载图像，查找描述符等开始。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" cv2 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" cv\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n\nimg1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# queryImage")]),s._v("\nimg2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box_in_scene.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# trainImage")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Initiate ORB detector")]),s._v("\norb "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("ORB_create"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# find the keypoints and descriptors with ORB")]),s._v("\nkp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" orb"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nkp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" orb"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("p",[s._v("接下来，我们使用距离测量cv.NORM_HAMMING创建一个BFMatcher对象（因为我们使用的是ORB）,并且启用了crossCheck以获得更好的结果。然后我们使用Matcher.match()方法在两个图像中获得最佳匹配。我们按照距离的升序对它们进行排序，以便最佳匹配（低距离）出现在前面。然后我们只绘制前10场比赛（太多了看不清，如果愿意的话你可以多画几条）")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# create BFMatcher object")]),s._v("\nbf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BFMatcher"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("NORM_HAMMING"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" crossCheck"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Match descriptors.")]),s._v("\nmatches "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("match")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("des1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("des2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Sort them in the order of their distance.")]),s._v("\nmatches "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sorted")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("lambda")]),s._v(" x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("x"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("distance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Draw first 10 matches.")]),s._v("\nimg3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drawMatches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" flags"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imshow"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])]),t("p",[s._v("结果如下图所示：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://docs.opencv.org/4.0.0/matcher_result1.jpg",alt:"image21"}})]),s._v(" "),t("h3",{attrs:{id:"这个matcher对象是什么？"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#这个matcher对象是什么？"}},[s._v("#")]),s._v(" 这个Matcher对象是什么？")]),s._v(" "),t("p",[s._v("matches = bf.match(des1，des2)行的结果是DMatch对象的列表。此DMatch对象具有以下属性：")]),s._v(" "),t("ul",[t("li",[s._v("DMatch.distance - 描述符之间的距离。越低越好。")]),s._v(" "),t("li",[s._v("DMatch.trainIdx - 列车描述符中描述符的索引")]),s._v(" "),t("li",[s._v("DMatch.queryIdx - 查询描述符中描述符的索引")]),s._v(" "),t("li",[s._v("DMatch.imgIdx - 火车图像的索引。")])]),s._v(" "),t("h3",{attrs:{id:"对-sift-描述符进行蛮力匹配和比值测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#对-sift-描述符进行蛮力匹配和比值测试"}},[s._v("#")]),s._v(" 对 SIFT 描述符进行蛮力匹配和比值测试")]),s._v(" "),t("p",[s._v("这一次，我们将使用BFMatcher.knnMatch()来获得最佳匹配。在这个例子中，我们将采用k = 2，以便我们可以在他的论文中应用D.Lowe解释的比率测试。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" cv2 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" cv\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" matplotlib "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n\nimg1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# queryImage")]),s._v("\nimg2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box_in_scene.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# trainImage")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Initiate SIFT detector")]),s._v("\nsift "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SIFT"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# find the keypoints and descriptors with SIFT")]),s._v("\nkp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nkp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# BFMatcher with default params")]),s._v("\nbf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("BFMatcher"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmatches "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" bf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("knnMatch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("des1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("des2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" k"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Apply ratio test")]),s._v("\ngood "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("distance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.75")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("distance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        good"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("append"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n        \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# cv.drawMatchesKnn expects list of lists as matches.")]),s._v("\nimg3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drawMatchesKnn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("good"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("flags"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imshow"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br")])]),t("p",[s._v("结果如下图所示：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://raw.githubusercontent.com/TonyStark1997/OpenCV-Python/master/5.Feature%20Detection%20and%20Description/Image/image22.jpg",alt:"image22"}})]),s._v(" "),t("h2",{attrs:{id:"flann匹配"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#flann匹配"}},[s._v("#")]),s._v(" FLANN匹配")]),s._v(" "),t("p",[s._v("FLANN 是快速最近邻搜索包（Fast_Library_for_Approximate_Nearest_Neighbors）的简称。它是一个对大数据集和高维特征进行最近邻搜索的算法的集合，而且这些算法都已经被优化过了。在面对大数据集时它的效果要好于 BFMatcher。我们将看到基于FLANN的匹配器的第二个示例。")]),s._v(" "),t("p",[s._v("对于基于FLANN的匹配器，我们需要传递两个字典，指定要使用的算法和其他相关参数等。首先是IndexParams。对于各种算法，要传递的信息在FLANN文档中进行了解。总而言之，对于像SIFT，SURF等算法，你可以传递以下内容：")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("FLANN_INDEX_KDTREE "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\nindex_params "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("algorithm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" FLANN_INDEX_KDTREE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" trees "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("p",[s._v("但使用 ORB 时，我们要传入的参数如下。注释掉的值是文献中推荐使用的，但是它们并不适合所有情况，其他值的效果可能会更好。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("FLANN_INDEX_LSH "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("\nindex_params"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("algorithm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" FLANN_INDEX_LSH"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                   table_number "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 12")]),s._v("\n                   key_size "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("     "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 20")]),s._v("\n                   multi_probe_level "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#2")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br")])]),t("p",[s._v("第二个字典是SearchParams。它指定应递归遍历索引中的树的次数。值越高，精度越高，但也需要更多时间。如果要更改该值，请传递search_params = dict(checks = 100)。")]),s._v(" "),t("p",[s._v("有了这些信息，我们就可以开始工作了。")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" cv2 "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" cv\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" matplotlib "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n\nimg1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# queryImage")]),s._v("\nimg2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imread"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'box_in_scene.png'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# trainImage")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Initiate SIFT detector")]),s._v("\nsift "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("SIFT"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# find the keypoints and descriptors with SIFT")]),s._v("\nkp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nkp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" des2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" sift"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("detectAndCompute"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# FLANN parameters")]),s._v("\nFLANN_INDEX_KDTREE "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\nindex_params "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("algorithm "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" FLANN_INDEX_KDTREE"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" trees "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsearch_params "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("checks"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# or pass empty dictionary")]),s._v("\n\nflann "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("FlannBasedMatcher"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("index_params"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("search_params"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nmatches "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" flann"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("knnMatch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("des1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("des2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("k"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Need to draw only good matches, so create a mask")]),s._v("\nmatchesMask "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("xrange")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ratio test as per Lowe's paper")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("enumerate")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" m"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("distance "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v("n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("distance"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        matchesMask"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("i"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n        \ndraw_params "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("dict")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("matchColor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                   singlePointColor "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                   matchesMask "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" matchesMask"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n                   flags "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nimg3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" cv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drawMatchesKnn"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("img2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("kp2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("matches"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("**")]),s._v("draw_params"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("imshow"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("img3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("plt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br")])]),t("p",[s._v("结果如下图所示：")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://docs.opencv.org/4.0.0/matcher_flann.jpg",alt:"image23"}})])])}),[],!1,null,null,null);t.default=e.exports}}]);