(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{333:function(t,e,a){"use strict";a.r(e);var s=a(11),_=Object(s.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("p",[t._v("随着目标检测算法的快速发展，以及终端应用的日渐广泛，工业界对深度学习网络在终端应用的关注度越来越高，尤其是对于如何保持速度和精度上的平衡，也形成了不小的研究热度。本篇整理了一些较新的轻量级目标检测网络，结合我们自己的目标，所选的网络参数量多在4M以下。")]),t._v(" "),e("h4",{attrs:{id:"_1-yolo-nano"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-yolo-nano"}},[t._v("#")]),t._v(" 1. YOLO Nano")]),t._v(" "),e("p",[t._v("YOLO Nano是一个高度紧凑的网络，它是一个基于YOLO网络的8位量化模型，并在PASCAL VOC 2007数据集上进行了优化。模型大小在4M左右，在计算上需要4.57B推算，性能表现上，在VOC 2007数据集上得到了69.1%的mAP。该网络非常适合边缘设备与移动端的实时检测。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://arxiv.org/abs/1910.01271",title:"https://arxiv.org/abs/1910.01271",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/abs/1910.01271"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("代码地址："),e("a",{attrs:{href:"https://github.com/liux0614/yolo_nano",title:"GitHub - liux0614/yolo_nano: Unofficial implementation of yolo nano",target:"_blank",rel:"noopener noreferrer"}},[t._v("GitHub - liux0614/yolo_nano: Unofficial implementation of yolo nano"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("YOLO Nano与Tiny YOLOv2、Tiny YOLOv3的对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/dd072c4fe31844d3877b8d2a4dff5b73.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_2-micro-yolo"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-micro-yolo"}},[t._v("#")]),t._v(" 2. Micro-YOLO")]),t._v(" "),e("p",[t._v("Micro-YOLO基于YOLOv3-Tiny，它在保持检测性能的同时显着减少了参数数量和计算成本。研究者建议将YOLOv3-tiny网络中的卷积层替换为深度分布偏移卷积(DSConv：https://arxiv.org/abs/1901.01928v1)和带有squeeze和excitation块的移动反向瓶颈卷积 (MBConv：主要源自于EfficientNet)，并设计渐进式通道级剪枝算法以最小化数量参数并最大化检测性能。")]),t._v(" "),e("p",[t._v("该网络尚未找到开源实现。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://www.scitepress.org/Papers/2021/102344/102344.pdf",title:"https://www.scitepress.org/Papers/2021/102344/102344.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.scitepress.org/Papers/2021/102344/102344.pdf"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("Micro-YOLO模型的参数量、乘加数可参见下表：")]),t._v(" "),e("h4",{attrs:{id:""}},[e("a",{staticClass:"header-anchor",attrs:{href:"#"}},[t._v("#")]),t._v(" "),e("img",{attrs:{src:"https://img-blog.csdnimg.cn/d3df7b65d84d4e08a698e0eaea3c8ed3.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_3-nanodet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-nanodet"}},[t._v("#")]),t._v(" 3. NanoDet")]),t._v(" "),e("p",[t._v("NanoDet是一款超快速、高精度、anchor-free的轻量级检测网络，可实现在移动设备上的实时运行。主要面向工程应用，暂未有论文发表。")]),t._v(" "),e("p",[t._v("工程链接："),e("a",{attrs:{href:"https://github.com/RangiLyu/nanodet",title:"GitHub - RangiLyu/nanodet: NanoDet-Plus",target:"_blank",rel:"noopener noreferrer"}},[t._v("GitHub - RangiLyu/nanodet: NanoDet-Plus"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("该网络具有如下特性：")]),t._v(" "),e("ul",[e("li",[t._v("超轻量级：模型文件只有0.98MB(INT8)或1.8MB(FP16)；")]),t._v(" "),e("li",[t._v("推理速度快：在移动ARM CPU上可达到97fps，即每帧10.23ms的推理速度；")]),t._v(" "),e("li",[t._v("高精度：CPU实时推理下最高可达34.3 mAPval@0.5:0.95；")]),t._v(" "),e("li",[t._v("训练友好：比其他模型具有明显小的GPU memory消耗，在GTX1060 6G0上可做到batch-size=80；")]),t._v(" "),e("li",[t._v("方便部署：支持各种后端，包括ncnn、MNN和OpenVINO。并且提供了基于ncnn推理框架的Android演示。")])]),t._v(" "),e("p",[t._v("NanoDet-Plus在NanoDet基础上进行了更进一步的优化，增加了AGM(Assign Guidance Module) 和DSLA(Dynamic Soft Label Assigner)模块，使精度在COCO dataset上有了7个点的 mAP提升(与NanoDet相比提升了30%左右)，且使得训练和部署更容易。")]),t._v(" "),e("p",[t._v("NanoDet-Plus整体架构图：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/df5e51438b594d05abcd15537da36f64.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("模型表现对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/1faee16ed47946a5bb450a7464d976c5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_4-yolox-nano"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4-yolox-nano"}},[t._v("#")]),t._v(" 4. YOLOX-Nano")]),t._v(" "),e("p",[t._v("YOLOX是在YOLO系列的基础上进行了若干改进生成的新的高性能检测器。要点包括：(1) Anchor-free的检测方式；(2) 检测头解耦；(3) 先进的标签分配策略SimOTA；(4)强数据增广；(5) Multi positives。其中，YOLOX-Nano只有0.91M的参数量和1.08G FLOPs，在COCO数据集上获得了25.3%的mAP，比NanoDet高1.8% mAP。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://arxiv.org/abs/2107.08430",title:"https://arxiv.org/abs/2107.08430",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/abs/2107.08430"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("代码地址："),e("a",{attrs:{href:"https://github.com/Megvii-BaseDetection/YOLOX",title:"https://github.com/Megvii-BaseDetection/YOLOX",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/Megvii-BaseDetection/YOLOX"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("下图给出了YOLO和YOLOX在检测头结构上的区别：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/7c2f308aa58d4bdeb4bd6953e856318b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("两种检测头在训练时的收敛情况如下图所示：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/6fa6c3aaf56f489eb766cc46ee8fccf0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("论文中给出了YOLOX-Nano与其他轻量级网络的对比。")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/772ae46f9f264a168fc65630c0b54760.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("更多图形化对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/c9964c17d4c144c2827064ff4a7d5d7b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_5-华为ghostnet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_5-华为ghostnet"}},[t._v("#")]),t._v(" 5. 华为GhostNet")]),t._v(" "),e("p",[t._v("GhostNet通过Ghost模块构建高效的神经网络结构，从而减少神经网络的计算成本。Ghost模块将原始卷积层分为两部分，首先使用较少的卷积核来生成原始特征图，然后，进一步使用廉价变换操作以高效生产更多幻影特征图。在基准模型和数据集上进行的实验表明，该方法是一个即插即用的模块，能够将原始模型转换为更紧凑的模型，同时保持可比的性能。此外，在效率和准确性方面，使用提出的新模块构建的GhostNet均优于最新的轻量神经网络，如MobileNetV3。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://arxiv.org/pdf/1911.11907.pdf",title:"https://arxiv.org/pdf/1911.11907.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/pdf/1911.11907.pdf"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("代码地址："),e("a",{attrs:{href:"https://github.com/huawei-noah/ghostnet",title:"GhostNet",target:"_blank",rel:"noopener noreferrer"}},[t._v("GhostNet"),e("OutboundLink")],1)]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/4c3243e0088042ee97e463fb4650b3c2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/b27c22d1d3ae4c1eb8036cd7ee75fd90.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#-2"}},[t._v("#")]),t._v(" "),e("img",{attrs:{src:"https://img-blog.csdnimg.cn/822f1147c3794f8a8b741cbb63501a8e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_6-yolov5"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_6-yolov5"}},[t._v("#")]),t._v(" 6. YOLOv5")]),t._v(" "),e("p",[t._v("代码地址："),e("a",{attrs:{href:"https://github.com/ultralytics/yolov5",title:"YOLOv5",target:"_blank",rel:"noopener noreferrer"}},[t._v("YOLOv5"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("YOLOv5是一系列目标检测架构的合集，其高精度、低耗时、易训练、易部署、好上手等特点，让YOLOv5的热度一举超过YOLOv4，成为当前目标检测界的主流。并且作者也一直在维护，新版本精度越来越高、速度越来越快、模型越来越小，截至目前为止，YOLOv5已经迭代到了第六个版本。为了应对移动端的部署应用，作者推出了YOLOv5的n版本，其参数量只有1.9M，在COCO val2007 dataset上的mAP精度也达到了28.4，而YOLOv5n6在YOLOv5n的基础上，mAP又有所提升，达到了34，同时模型参数量提升到3.2M。")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/8cd4a5d343af41cfa477a3a940997106.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("推理和精度：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/664387f443b44f96a3f6b2a01dbc12e5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_7-yolo-fastest"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_7-yolo-fastest"}},[t._v("#")]),t._v(" 7. YOLO-Fastest")]),t._v(" "),e("p",[t._v("Yolo-Fastest注重的是单核的实时推理性能，在满足实时的条件下的低CPU占用。目前Yolo-Fastest更新到了V2版本。")]),t._v(" "),e("p",[t._v("工程地址：")]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/dog-qiuqiu/Yolo-FastestV2",title:"YOLO-FastestV2",target:"_blank",rel:"noopener noreferrer"}},[t._v("YOLO-FastestV2"),e("OutboundLink")],1)]),t._v(" "),e("p",[e("a",{attrs:{href:"https://github.com/dog-qiuqiu/Yolo-Fastest",title:"YOLO-Fastest",target:"_blank",rel:"noopener noreferrer"}},[t._v("YOLO-Fastest"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("模型特点：")]),t._v(" "),e("ul",[e("li",[t._v("简单、快速、紧凑、易于移植；")]),t._v(" "),e("li",[t._v("占用资源少，单核性能优异，功耗低；")]),t._v(" "),e("li",[t._v("基于yolo的已知最快最小通用目标检测算法；")]),t._v(" "),e("li",[t._v("适用于所有平台的实时目标检测算法；")]),t._v(" "),e("li",[t._v("ARM移动终端优化设计，优化支持NCNN推理框架。")]),t._v(" "),e("li",[t._v("训练速度快，计算能力要求低，训练只需要3GB视频内存，gtx1660ti训练COCO 1 epoch只需4分钟。")])]),t._v(" "),e("p",[t._v("V2版本相对于V1版本更快更小：以0.3%的精度损失换取30%的推理速度提高，参数数量减少25%。")]),t._v(" "),e("p",[t._v("数据对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/687c875ca747474399f144fe927a7035.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/544c94b75b5149dca4d6dc1ef86d4799.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_8-yolov5-lite"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_8-yolov5-lite"}},[t._v("#")]),t._v(" 8. YOLOv5-Lite")]),t._v(" "),e("p",[t._v("YOLOv5-Lite为轻量型的YOLOv5改进版本，整体算法与YOLOv5基本一致，通过修改了YOLOv5的backbone达到模型压缩的目的。根据不同的backbone分别提供了e、s、c、g版本，e版本的backbone为shufflenetv2，s版本的backbone也是shufflenetv2 (与e版本的head不同)，c版本的backbone为PPLcnet，g版本的backbone为Repvgg。")]),t._v(" "),e("p",[t._v("工程地址："),e("a",{attrs:{href:"https://github.com/ppogg/YOLOv5-Lite",title:"YOLOv5-Lite",target:"_blank",rel:"noopener noreferrer"}},[t._v("YOLOv5-Lite"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("与各个轻量级算法的精度对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/aca6ed103fb746b3a83f2e8a49293af2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("各模型的backbone、head以及适用的平台可参加下面几个表：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/a8688515be8d4556ac68132fdd6be53e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/6d3fae9cb87e433d8de9e755ac904789.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/dfb5d54e1eac41889b48ded1f775966f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/e9de7bf999e94608bdd1f1872fbb3fcb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_9-yolobile"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_9-yolobile"}},[t._v("#")]),t._v(" 9. YOLObile")]),t._v(" "),e("p",[t._v("YOLObile，顾名思义，是一种适用于移动设备的轻量级网络，从压缩、编译两个角度，在保证模型准确率的基础上，减少模型的大小，并提升模型在移动设备端的运行速度。新的YOLObile framework将YOLOv4压缩了14倍，准确率保持在49.0mAP。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://arxiv.org/pdf/2009.05697.pdf",title:"https://arxiv.org/pdf/2009.05697.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/pdf/2009.05697.pdf"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("代码地址："),e("a",{attrs:{href:"https://github.com/nightsnack/YOLObile",title:"YOLObile",target:"_blank",rel:"noopener noreferrer"}},[t._v("YOLObile"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("YOLObile使用了一种新的block-punched剪枝技术，并且为了提高在移动设备上的计算效率，采用了GPU-CPU协作方案以及高级编译器辅助优化。YOLObile在三星Galaxy S20 GPU上达到17FPS的帧率，使用GPU-CPU协作方案可将帧率提升至19.1 FPS，比YOLOv4的速度提升了5倍。")]),t._v(" "),e("p",[t._v("YOLObile与其他模型在精度和速度上的对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/1913ca2b3281487fbf28d6ec68e4d445.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("h4",{attrs:{id:"_10-pp-picodet"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_10-pp-picodet"}},[t._v("#")]),t._v(" 10. PP-PicoDet")]),t._v(" "),e("p",[t._v("PP-PicoDet是基于百度PaddleDetection提出的面向移动端和CPU的轻量级检测模型，在移动设备上具有卓越的性能，成为全新的SOTA轻量级模型，并且一直在更新维护，最新的版本发布于2022年3月20日。")]),t._v(" "),e("p",[t._v("论文地址："),e("a",{attrs:{href:"https://arxiv.org/abs/2111.00869",title:"https://arxiv.org/abs/2111.00869",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://arxiv.org/abs/2111.00869"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("工程链接："),e("a",{attrs:{href:"https://github.com/PaddlePaddle/PaddleDetection/tree/release/2.4/configs/picodet",title:"PaddlePaddle/PaddleDetection",target:"_blank",rel:"noopener noreferrer"}},[t._v("PaddlePaddle/PaddleDetection"),e("OutboundLink")],1)]),t._v(" "),e("p",[t._v("PP-PicoDet模型具有如下特点：")]),t._v(" "),e("ul",[e("li",[t._v("更高的mAP，参数量在1M以内，在输入像素416x416时，mAP超过30；")]),t._v(" "),e("li",[t._v("更快的预测速度，在ARM CPU上可达到150FPS；")]),t._v(" "),e("li",[t._v("部署友好，支持PaddleLite、MNN、MCNN、OpenVINO等平台，支持转换ONNX，并且提供了C++/Python/Android的Demo；")]),t._v(" "),e("li",[t._v("算法创新，在现有SOTA算法上进行了优化，包括ESNet、CSP-PAN、SimOTA等。")])]),t._v(" "),e("p",[t._v("模型架构：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/e6c14ab9814742a890d49be444b7e9e7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("模型参数量、FLOPs等数据如下表所示：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/6bc89a8ebe5b432f856a6aa641e12d09.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("更多模型对比：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/c7cc03a20c184b98859a34edab89f71b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})]),t._v(" "),e("p",[t._v("各移动端模型在COCO数据集上精度mAP和高通骁龙865处理器上预测速度(FPS)对比图：")]),t._v(" "),e("p",[e("img",{attrs:{src:"https://img-blog.csdnimg.cn/0a2fd0c4931840c3a9b58fbbabcef7c6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA54mn576K5aWz6K-0,size_20,color_FFFFFF,t_70,g_se,x_16",alt:""}})])])}),[],!1,null,null,null);e.default=_.exports}}]);