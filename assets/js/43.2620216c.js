(window.webpackJsonp=window.webpackJsonp||[]).push([[43],{361:function(s,t,e){"use strict";e.r(t);var n=e(11),a=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("p",[s._v("目前OpenCV4.2版本中自带了8个目标跟踪算法的实现。")]),s._v(" "),t("ul",[t("li",[s._v("**BOOSTING：**算法原理类似于Haar cascades (AdaBoost)，是一种很老的算法。这个算法速度慢并且不是很准。")]),s._v(" "),t("li",[t("strong",[s._v("MIL："),t("strong",[s._v("比")]),s._v("BOOSTING")]),s._v("准一点。")]),s._v(" "),t("li",[t("strong",[s._v("KCF："),t("strong",[s._v("速度比")]),s._v("BOOSTING")]),s._v("和"),t("strong",[s._v("MIL")]),s._v("更快，与"),t("strong",[s._v("BOOSTING")]),s._v("和"),t("strong",[s._v("MIL")]),s._v("一样不能很好地处理遮挡问题。")]),s._v(" "),t("li",[t("strong",[s._v("CSRT："),t("strong",[s._v("比")]),s._v("KCF")]),s._v("更准一些，但是速度比"),t("strong",[s._v("KCF")]),s._v("稍慢。")]),s._v(" "),t("li",[s._v("**MedianFlow：**对于快速移动的目标和外形变化迅速的目标效果不好。")]),s._v(" "),t("li",[s._v("**TLD：**会产生较多的false-positives。")]),s._v(" "),t("li",[t("strong",[s._v("MOSSE："),t("strong",[s._v("算法速度非常快，但是准确率比不上")]),s._v("KCF")]),s._v("和**CSRT。**在一些追求算法速度的场合很适用。")]),s._v(" "),t("li",[s._v("**GOTURN：**OpenCV中自带的唯一一个基于深度学习的算法。运行算法需要提前下载好模型文件。")])]),s._v(" "),t("p",[s._v("综合算法速度和准确率考虑，个人觉得"),t("strong",[s._v("CSRT、KCF、MOSSE")]),s._v("这三个目标跟踪算法较好。")]),s._v(" "),t("h2",{attrs:{id:"使用opencv来目标跟踪"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用opencv来目标跟踪"}},[s._v("#")]),s._v(" 使用OpenCV来目标跟踪")]),s._v(" "),t("p",[s._v("新建文件opencv_objecttracking.py。代码如下，首先使用TrackerXXX_create()方法创建目标跟踪类对象，然后调用tracker.init方法初始化需要跟踪的目标，这里使用了cv2.selectROI来手动选择目标框，然后使用tracker.update方法来跟踪目标，最后将跟踪结果可视化出来。")]),s._v(" "),t("div",{staticClass:"language-python3 line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v('# import the necessary packages\nfrom imutils.video import VideoStream\nfrom imutils.video import FPS\nimport argparse\nimport imutils\nimport time\nimport cv2\n\n# construct the argument parser and parse the arguments\nap = argparse.ArgumentParser()\nap.add_argument("-v", "--video", type=str,\n\thelp="path to input video file")\nap.add_argument("-t", "--tracker", type=str, default="kcf",\n\thelp="OpenCV object tracker type")\nargs = vars(ap.parse_args())\n\n# extract the OpenCV version info\n(major, minor) = cv2.__version__.split(".")[:2]\n# if we are using OpenCV 3.2 OR BEFORE, we can use a special factory\n# function to create our object tracker\nif int(major) == 3 and int(minor) < 3:\n\ttracker = cv2.Tracker_create(args["tracker"].upper())\n# otherwise, for OpenCV 3.3 OR NEWER, we need to explicity call the\n# approrpiate object tracker constructor:\nelse:\n\t# initialize a dictionary that maps strings to their corresponding\n\t# OpenCV object tracker implementations\n\tOPENCV_OBJECT_TRACKERS = {\n\t\t"csrt": cv2.TrackerCSRT_create,\n\t\t"kcf": cv2.TrackerKCF_create,\n\t\t"boosting": cv2.TrackerBoosting_create,\n\t\t"mil": cv2.TrackerMIL_create,\n\t\t"tld": cv2.TrackerTLD_create,\n\t\t"medianflow": cv2.TrackerMedianFlow_create,\n\t\t"mosse": cv2.TrackerMOSSE_create\n\t}\n\t# grab the appropriate object tracker using our dictionary of\n\t# OpenCV object tracker objects\n\ttracker = OPENCV_OBJECT_TRACKERS[args["tracker"]]()\n# initialize the bounding box coordinates of the object we are going\n# to track\ninitBB = None\n\n# if a video path was not supplied, grab the reference to the web cam\nif not args.get("video", False):\n\tprint("[INFO] starting video stream...")\n\tvs = VideoStream(src=0).start()\n\ttime.sleep(1.0)\n# otherwise, grab a reference to the video file\nelse:\n\tvs = cv2.VideoCapture(args["video"])\n# initialize the FPS throughput estimator\nfps = None\n\n# loop over frames from the video stream\nwhile True:\n\t# grab the current frame, then handle if we are using a\n\t# VideoStream or VideoCapture object\n\tframe = vs.read()\n\tframe = frame[1] if args.get("video", False) else frame\n\t# check to see if we have reached the end of the stream\n\tif frame is None:\n\t\tbreak\n\t# resize the frame (so we can process it faster) and grab the\n\t# frame dimensions\n\tframe = imutils.resize(frame, width=500)\n\t(H, W) = frame.shape[:2]\n\n\t# check to see if we are currently tracking an object\n\tif initBB is not None:\n\t\t# grab the new bounding box coordinates of the object\n\t\t(success, box) = tracker.update(frame)\n\t\t# check to see if the tracking was a success\n\t\tif success:\n\t\t\t(x, y, w, h) = [int(v) for v in box]\n\t\t\tcv2.rectangle(frame, (x, y), (x + w, y + h),\n\t\t\t\t(0, 255, 0), 2)\n\t\t# update the FPS counter\n\t\tfps.update()\n\t\tfps.stop()\n\t\t# initialize the set of information we\'ll be displaying on\n\t\t# the frame\n\t\tinfo = [\n\t\t\t("Tracker", args["tracker"]),\n\t\t\t("Success", "Yes" if success else "No"),\n\t\t\t("FPS", "{:.2f}".format(fps.fps())),\n\t\t]\n\t\t# loop over the info tuples and draw them on our frame\n\t\tfor (i, (k, v)) in enumerate(info):\n\t\t\ttext = "{}: {}".format(k, v)\n\t\t\tcv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n\n\t# show the output frame\n\tcv2.imshow("Frame", frame)\n\tkey = cv2.waitKey(1) & 0xFF\n\t# if the \'s\' key is selected, we are going to "select" a bounding\n\t# box to track\n\tif key == ord("s"):\n\t\t# select the bounding box of the object we want to track (make\n\t\t# sure you press ENTER or SPACE after selecting the ROI)\n\t\tinitBB = cv2.selectROI("Frame", frame, fromCenter=False,\n\t\t\tshowCrosshair=True)\n\t\t# start OpenCV object tracker using the supplied bounding box\n\t\t# coordinates, then start the FPS throughput estimator as well\n\t\ttracker.init(frame, initBB)\n\t\tfps = FPS().start()\n\n\t# if the `q` key was pressed, break from the loop\n\telif key == ord("q"):\n\t\tbreak\n# if we are using a webcam, release the pointer\nif not args.get("video", False):\n\tvs.stop()\n# otherwise, release the file pointer\nelse:\n\tvs.release()\n# close all windows\ncv2.destroyAllWindows()\n')])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br"),t("span",{staticClass:"line-number"},[s._v("84")]),t("br"),t("span",{staticClass:"line-number"},[s._v("85")]),t("br"),t("span",{staticClass:"line-number"},[s._v("86")]),t("br"),t("span",{staticClass:"line-number"},[s._v("87")]),t("br"),t("span",{staticClass:"line-number"},[s._v("88")]),t("br"),t("span",{staticClass:"line-number"},[s._v("89")]),t("br"),t("span",{staticClass:"line-number"},[s._v("90")]),t("br"),t("span",{staticClass:"line-number"},[s._v("91")]),t("br"),t("span",{staticClass:"line-number"},[s._v("92")]),t("br"),t("span",{staticClass:"line-number"},[s._v("93")]),t("br"),t("span",{staticClass:"line-number"},[s._v("94")]),t("br"),t("span",{staticClass:"line-number"},[s._v("95")]),t("br"),t("span",{staticClass:"line-number"},[s._v("96")]),t("br"),t("span",{staticClass:"line-number"},[s._v("97")]),t("br"),t("span",{staticClass:"line-number"},[s._v("98")]),t("br"),t("span",{staticClass:"line-number"},[s._v("99")]),t("br"),t("span",{staticClass:"line-number"},[s._v("100")]),t("br"),t("span",{staticClass:"line-number"},[s._v("101")]),t("br"),t("span",{staticClass:"line-number"},[s._v("102")]),t("br"),t("span",{staticClass:"line-number"},[s._v("103")]),t("br"),t("span",{staticClass:"line-number"},[s._v("104")]),t("br"),t("span",{staticClass:"line-number"},[s._v("105")]),t("br"),t("span",{staticClass:"line-number"},[s._v("106")]),t("br"),t("span",{staticClass:"line-number"},[s._v("107")]),t("br"),t("span",{staticClass:"line-number"},[s._v("108")]),t("br"),t("span",{staticClass:"line-number"},[s._v("109")]),t("br"),t("span",{staticClass:"line-number"},[s._v("110")]),t("br"),t("span",{staticClass:"line-number"},[s._v("111")]),t("br"),t("span",{staticClass:"line-number"},[s._v("112")]),t("br"),t("span",{staticClass:"line-number"},[s._v("113")]),t("br"),t("span",{staticClass:"line-number"},[s._v("114")]),t("br"),t("span",{staticClass:"line-number"},[s._v("115")]),t("br"),t("span",{staticClass:"line-number"},[s._v("116")]),t("br"),t("span",{staticClass:"line-number"},[s._v("117")]),t("br"),t("span",{staticClass:"line-number"},[s._v("118")]),t("br"),t("span",{staticClass:"line-number"},[s._v("119")]),t("br")])]),t("p",[s._v("命令行运行：")]),s._v(" "),t("div",{staticClass:"language-text line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("python opencv_object_tracking.py --tracker kcf\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("结果如下：")]),s._v(" "),t("p",[t("a",{attrs:{href:"https://www.zhihu.com/video/1225111409124065280",target:"_blank",rel:"noopener noreferrer"}},[t("img",{attrs:{src:"https://pic2.zhimg.com/v2-86adf21e18bfd776b5f68769bb667d91.jpg",alt:""}}),s._v("https://www.zhihu.com/video/1225111409124065280"),t("OutboundLink")],1)]),s._v(" "),t("p",[s._v("看起来像目标检测一样，但是用的不是目标检测算法，用的是目标跟踪算法，速度比目标检测快得多。可以看到在CPU上达到了接近60的FPS。")]),s._v(" "),t("p",[s._v("另外关于多目标跟踪可以使用OpenCV中的cv2.MultiTracker_create()。本质是为每一个跟踪目标新建一个跟踪类，然后添加到一个集合中，在每次更新时将所有跟踪目标更新一遍。")])])}),[],!1,null,null,null);t.default=a.exports}}]);