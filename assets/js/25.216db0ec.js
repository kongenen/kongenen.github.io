(window.webpackJsonp=window.webpackJsonp||[]).push([[25],{345:function(s,n,e){"use strict";e.r(n);var t=e(11),a=Object(t.a)({},(function(){var s=this,n=s._self._c;return n("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[n("blockquote",[n("p",[s._v("该文主要是对yolov8的检测、分类、分割、姿态应用使用c++进行dll封装，并进行调用测试。")])]),s._v(" "),n("h2",{attrs:{id:"_0-模型准备"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_0-模型准备"}},[s._v("#")]),s._v(" 0. 模型准备")]),s._v(" "),n("p",[s._v("openvino调用的是xml和bin文件（下面的推理方式只需要调用xml的文件就行，另外一篇（"),n("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_44747572/article/details/134003776%3Fspm%3D1001.2014.3001.5501",target:"_blank",rel:"noopener noreferrer"}},[s._v("链接"),n("OutboundLink")],1),s._v("）使用xml和bin文件调用的）。 文件的获取过程（yolov8是pytorch训练的）： "),n("strong",[s._v("pt->onnx->openvino（xml和bin）")])]),s._v(" "),n("h3",{attrs:{id:"方法一：（使用这种，由于版本不一致，推理失败）"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法一：（使用这种，由于版本不一致，推理失败）"}},[s._v("#")]),s._v(" 方法一：（使用这种，由于版本不一致，推理失败）")]),s._v(" "),n("p",[s._v("使用yolov8自带的代码进行转换，这个过程比较方便，但是对于后续部署其他的模型不太方便。")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v('path = model.export(format="openvino")这行代码可以直接将yolov8n-pose.pt模型转换为xml和bin文件\n# 加载预训练模型\n    model = YOLO("yolov8n-pose.pt") \n    #path = model.export(format="onnx")\n    path = model.export(format="openvino")\n    # model = YOLO("yolov8n.pt") task参数也可以不填写，它会根据模型去识别相应任务类别\n    # 检测图片\n    results = model("./ultralytics/assets/bus.jpg")\n    res = results[0].plot()\n    cv2.imshow("YOLOv8 Inference", res)\n    cv2.waitKey(0)\n\n')])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br")])]),n("p",[n("img",{attrs:{src:"https://pic4.zhimg.com/v2-6834398a16ddd42ae281a3f1a2f532ab_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("h3",{attrs:{id:"方法二："}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法二："}},[s._v("#")]),s._v(" 方法二：")]),s._v(" "),n("ol",[n("li",[s._v("使用python的环境进行配置："),n("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/download.html%3FVERSION%3Dv_2023_1_0%26OP_SYSTEM%3DWINDOWS%26DISTRIBUTION%3DPIP",target:"_blank",rel:"noopener noreferrer"}},[s._v("pip下载方法"),n("OutboundLink")],1)])]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic4.zhimg.com/v2-ac20f923504f97a0a0243804579d367b_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic4.zhimg.com/v2-b2fe90bed77301c48e3508115635b293_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("p",[s._v("主要就是："),n("code",[s._v("pip install openvino==2023.1.0")])]),s._v(" "),n("ol",[n("li",[s._v("使用代码行进行推理 在对应的环境库中找到mo_onnx.py，在终端切换路径到mo_onnx.py的路径下，然后再使用下面的命令。")])]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("python mo_onnx.py --input_model D:\\Users\\6536\\Desktop\\python\\onnx2openvino\\yolov8n.onnx --output_dir D:\\Users\\6536\\Desktop\\python\\onnx2openvino\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br")])]),n("h3",{attrs:{id:"方法三：（推荐这种）"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#方法三：（推荐这种）"}},[s._v("#")]),s._v(" 方法三：（推荐这种）")]),s._v(" "),n("p",[n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/358437476",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://zhuanlan.zhihu.com/p/358437476"),n("OutboundLink")],1)]),s._v(" "),n("h2",{attrs:{id:"_1-ov-yolov8-dll"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-ov-yolov8-dll"}},[s._v("#")]),s._v(" 1. OV_YOLOV8_DLL")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic2.zhimg.com/v2-6ac377d205a511990af1afa550b2f8f1_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("h3",{attrs:{id:"_0-c-依赖项配置"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_0-c-依赖项配置"}},[s._v("#")]),s._v(" 0. c++依赖项配置")]),s._v(" "),n("p",[s._v("主要配置opencv以及openvino openvino的配置："),n("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_44747572/article/details/134003776%3Fspm%3D1001.2014.3001.5501",target:"_blank",rel:"noopener noreferrer"}},[s._v("链接"),n("OutboundLink")],1),s._v(" 所以配置截图：")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic2.zhimg.com/v2-b6af8b513c8c07ce759d66a9e9e5b461_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic1.zhimg.com/v2-2a71c5a170769e32823bad401cfe1490_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic1.zhimg.com/v2-bc916a159810b91441618235db7afda0_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("p",[n("img",{attrs:{src:"https://pic4.zhimg.com/v2-3a3bc9be8a0a24a25d112f63165297cf_r.jpg",alt:""}})]),s._v(" "),n("p",[s._v("在这里插入图片描述")]),s._v(" "),n("h3",{attrs:{id:"_1-ov-yolov8-cpp"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-ov-yolov8-cpp"}},[s._v("#")]),s._v(" 1. ov_yolov8.cpp")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v('#include "ov_yolov8.h"\n\n// 全局变量\nstd::vector<cv::Scalar> colors = { cv::Scalar(0, 0, 255) , cv::Scalar(0, 255, 0) , cv::Scalar(255, 0, 0) ,\n                               cv::Scalar(255, 100, 50) , cv::Scalar(50, 100, 255) , cv::Scalar(255, 50, 100) };\n\nstd::vector<Scalar> colors_seg = { Scalar(255, 0, 0), Scalar(255, 0, 255), Scalar(170, 0, 255), Scalar(255, 0, 85),\n                                   Scalar(255, 0, 170), Scalar(85, 255, 0), Scalar(255, 170, 0), Scalar(0, 255, 0),\n                                   Scalar(255, 255, 0), Scalar(0, 255, 85), Scalar(170, 255, 0), Scalar(0, 85, 255),\n                                   Scalar(0, 255, 170), Scalar(0, 0, 255), Scalar(0, 255, 255), Scalar(85, 0, 255) };\n\n// 定义skeleton的连接关系以及color mappings\nstd::vector<std::vector<int>> skeleton = { {16, 14}, {14, 12}, {17, 15}, {15, 13}, {12, 13}, {6, 12}, {7, 13}, {6, 7},\n                                          {6, 8}, {7, 9}, {8, 10}, {9, 11}, {2, 3}, {1, 2}, {1, 3}, {2, 4}, {3, 5}, {4, 6}, {5, 7} };\n\nstd::vector<cv::Scalar> posePalette = {\n        cv::Scalar(255, 128, 0), cv::Scalar(255, 153, 51), cv::Scalar(255, 178, 102), cv::Scalar(230, 230, 0), cv::Scalar(255, 153, 255),\n        cv::Scalar(153, 204, 255), cv::Scalar(255, 102, 255), cv::Scalar(255, 51, 255), cv::Scalar(102, 178, 255), cv::Scalar(51, 153, 255),\n        cv::Scalar(255, 153, 153), cv::Scalar(255, 102, 102), cv::Scalar(255, 51, 51), cv::Scalar(153, 255, 153), cv::Scalar(102, 255, 102),\n        cv::Scalar(51, 255, 51), cv::Scalar(0, 255, 0), cv::Scalar(0, 0, 255), cv::Scalar(255, 0, 0), cv::Scalar(255, 255, 255)\n};\n\nstd::vector<int> limbColorIndices = { 9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16 };\nstd::vector<int> kptColorIndices = { 16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9 };\n\nconst std::vector<std::string> class_names = {\n    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",\n    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",\n    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",\n    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",\n    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",\n    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",\n    "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",\n    "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",\n    "hair drier", "toothbrush" };\n\nYoloModel::YoloModel()\n{\n\n}\nYoloModel::~YoloModel()\n{\n\n}\n\n// =====================检测========================//\nbool YoloModel::LoadDetectModel(const string& xmlName, string& device)\n{\n    //待优化，如何把初始化部分进行提取出来\n   // -------- Step 1. Initialize OpenVINO Runtime Core --------\n    ov::Core core;\n\n    // -------- Step 2. Compile the Model --------\n    compiled_model_Detect = core.compile_model(xmlName, device);\n\n    // -------- Step 3. Create an Inference Request --------\n    infer_request_Detect = compiled_model_Detect.create_infer_request();\n\n    return true;\n}\n\nbool YoloModel::YoloDetectInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj)\n{\n    // -------- Step 4.Read a picture file and do the preprocess --------\n    // Preprocess the image\n    Mat letterbox_img;\n    letterbox(src, letterbox_img);\n    float scale = letterbox_img.size[0] / 640.0;\n    Mat blob = blobFromImage(letterbox_img, 1.0 / 255.0, Size(640, 640), Scalar(), true);\n\n    // -------- Step 5. Feed the blob into the input node of the Model -------\n    // Get input port for model with one input\n    auto input_port = compiled_model_Detect.input();\n    // Create tensor from external memory\n    ov::Tensor input_tensor(input_port.get_element_type(), input_port.get_shape(), blob.ptr(0));\n    // Set input tensor for model with one input\n    infer_request_Detect.set_input_tensor(input_tensor);\n    // -------- Step 6. Start inference --------\n    infer_request_Detect.infer();\n\n    // -------- Step 7. Get the inference result --------\n    auto output = infer_request_Detect.get_output_tensor(0);\n    auto output_shape = output.get_shape();\n    std::cout << "The shape of output tensor:" << output_shape << std::endl;\n    int rows = output_shape[2];        //8400\n    int dimensions = output_shape[1];  //84: box[cx, cy, w, h]+80 classes scores\n\n    // -------- Step 8. Postprocess the result --------\n    float* data = output.data<float>();\n    Mat output_buffer(output_shape[1], output_shape[2], CV_32F, data);\n    transpose(output_buffer, output_buffer); //[8400,84]\n    float score_threshold = 0.25;\n    float nms_threshold = 0.5;\n    std::vector<int> class_ids;\n    std::vector<float> class_scores;\n    std::vector<Rect> boxes;\n\n    // Figure out the bbox, class_id and class_score\n    for (int i = 0; i < output_buffer.rows; i++) {\n        Mat classes_scores = output_buffer.row(i).colRange(4, 84);\n        Point class_id;\n        double maxClassScore;\n        minMaxLoc(classes_scores, 0, &maxClassScore, 0, &class_id);\n\n        if (maxClassScore > score_threshold) {\n            class_scores.push_back(maxClassScore);\n            class_ids.push_back(class_id.x);\n            float cx = output_buffer.at<float>(i, 0);\n            float cy = output_buffer.at<float>(i, 1);\n            float w = output_buffer.at<float>(i, 2);\n            float h = output_buffer.at<float>(i, 3);\n\n            int left = int((cx - 0.5 * w) * scale);\n            int top = int((cy - 0.5 * h) * scale);\n            int width = int(w * scale);\n            int height = int(h * scale);\n\n            boxes.push_back(Rect(left, top, width, height));\n        }\n    }\n    //NMS\n    std::vector<int> indices;\n    NMSBoxes(boxes, class_scores, score_threshold, nms_threshold, indices);\n\n    // -------- Visualize the detection results -----------\n    dst = src.clone();\n    for (size_t i = 0; i < indices.size(); i++) {\n        int index = indices[i];\n        int class_id = class_ids[index];\n        rectangle(dst, boxes[index], colors[class_id % 6], 2, 8);\n        std::string label = class_names[class_id] + ":" + std::to_string(class_scores[index]).substr(0, 4);\n        Size textSize = cv::getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, 0);\n        Rect textBox(boxes[index].tl().x, boxes[index].tl().y - 15, textSize.width, textSize.height + 5);\n        cv::rectangle(dst, textBox, colors[class_id % 6], FILLED);\n        putText(dst, label, Point(boxes[index].tl().x, boxes[index].tl().y - 5), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(255, 255, 255));\n    }\n\n    return true;\n}\n\n// =====================分类========================//\nbool YoloModel::LoadClsModel(const string& xmlName, string& device)\n{\n    //待优化，如何把初始化部分进行提取出来\n   // -------- Step 1. Initialize OpenVINO Runtime Core --------\n    ov::Core core;\n\n    // -------- Step 2. Compile the Model --------\n    compiled_model_Detect_Cls = core.compile_model(xmlName, device);\n\n    // -------- Step 3. Create an Inference Request --------\n    infer_request_Cls = compiled_model_Detect_Cls.create_infer_request();\n\n    return true;\n}\n\nbool YoloModel::YoloClsInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj)\n{\n    // -------- Step 4.Read a picture file and do the preprocess --------\n    // Preprocess the image\n    Mat letterbox_img;\n    letterbox(src, letterbox_img);\n    float scale = letterbox_img.size[0] / 640.0;\n    Mat blob = blobFromImage(letterbox_img, 1.0 / 255.0, Size(224, 224), Scalar(), true);\n\n    // -------- Step 5. Feed the blob into the input node of the Model -------\n    // Get input port for model with one input\n    auto input_port = compiled_model_Detect_Cls.input();\n    // Create tensor from external memory\n    ov::Tensor input_tensor(input_port.get_element_type(), input_port.get_shape(), blob.ptr(0));\n    // Set input tensor for model with one input\n    infer_request_Cls.set_input_tensor(input_tensor);\n\n    // -------- Step 6. Start inference --------\n    infer_request_Cls.infer();\n\n    // -------- Step 7. Get the inference result --------\n    auto output = infer_request_Cls.get_output_tensor(0);\n    auto output_shape = output.get_shape();\n    std::cout << "The shape of output tensor:" << output_shape << std::endl;\n\n    // -------- Step 8. Postprocess the result --------\n    float* output_buffer = output.data<float>();\n    std::vector<float> result(output_buffer, output_buffer + output_shape[1]);\n    auto max_idx = std::max_element(result.begin(), result.end());\n    int class_id = max_idx - result.begin();\n    float score = *max_idx;\n    std::cout << "Class ID:" << class_id << " Score:" << score << std::endl;\n\n    return true;\n}\n\n// =====================分割========================//\nbool YoloModel::LoadSegModel(const string& xmlName, string& device)\n{\n    //待优化，如何把初始化部分进行提取出来\n   // -------- Step 1. Initialize OpenVINO Runtime Core --------\n    ov::Core core;\n\n    // -------- Step 2. Compile the Model --------\n    compiled_model_Seg = core.compile_model(xmlName, device);\n\n    // -------- Step 3. Create an Inference Request --------\n    infer_request_Seg = compiled_model_Seg.create_infer_request();\n\n    return true;\n}\n\nbool YoloModel::YoloSegInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj)\n{\n    // -------- Step 4.Read a picture file and do the preprocess --------\n    // Preprocess the image\n    Mat letterbox_img;\n    letterbox(src, letterbox_img);\n    float scale = letterbox_img.size[0] / 640.0;\n    Mat blob = blobFromImage(letterbox_img, 1.0 / 255.0, Size(640, 640), Scalar(), true);\n\n    // -------- Step 5. Feed the blob into the input node of the Model -------\n    // Get input port for model with one input\n    auto input_port = compiled_model_Seg.input();\n    // Create tensor from external memory\n    ov::Tensor input_tensor(input_port.get_element_type(), input_port.get_shape(), blob.ptr(0));\n    // Set input tensor for model with one input\n    infer_request_Seg.set_input_tensor(input_tensor);\n\n    // -------- Step 6. Start inference --------\n    infer_request_Seg.infer();\n\n    // -------- Step 7. Get the inference result --------\n    auto output0 = infer_request_Seg.get_output_tensor(0); //output0\n    auto output1 = infer_request_Seg.get_output_tensor(1); //otuput1\n    auto output0_shape = output0.get_shape();\n    auto output1_shape = output1.get_shape();\n    std::cout << "The shape of output0:" << output0_shape << std::endl;\n    std::cout << "The shape of output1:" << output1_shape << std::endl;\n\n    // -------- Step 8. Postprocess the result --------\n    Mat output_buffer(output1_shape[1], output1_shape[2], CV_32F, output1.data<float>());    // output_buffer 0:x 1:y  2 : w 3 : h   4--84 : class score  85--116 : mask pos\n    Mat proto(32, 25600, CV_32F, output0.data<float>()); //[32,25600] 1 32 160 160\n    transpose(output_buffer, output_buffer); //[8400,116]\n    std::vector<int> class_ids;\n    std::vector<float> class_scores;\n    std::vector<Rect> boxes;\n    std::vector<Mat> mask_confs;\n    // Figure out the bbox, class_id and class_score\n    for (int i = 0; i < output_buffer.rows; i++) {\n        Mat classes_scores = output_buffer.row(i).colRange(4, 84);\n        Point class_id;\n        double maxClassScore;\n        minMaxLoc(classes_scores, 0, &maxClassScore, 0, &class_id);\n\n        if (maxClassScore > cof_threshold) {\n            class_scores.push_back(maxClassScore);\n            class_ids.push_back(class_id.x);\n            float cx = output_buffer.at<float>(i, 0);\n            float cy = output_buffer.at<float>(i, 1);\n            float w = output_buffer.at<float>(i, 2);\n            float h = output_buffer.at<float>(i, 3);\n\n            int left = int((cx - 0.5 * w) * scale);\n            int top = int((cy - 0.5 * h) * scale);\n            int width = int(w * scale);\n            int height = int(h * scale);\n\n            cv::Mat mask_conf = output_buffer.row(i).colRange(84, 116);\n            mask_confs.push_back(mask_conf);\n            boxes.push_back(Rect(left, top, width, height));\n        }\n    }\n    //NMS\n    std::vector<int> indices;\n    NMSBoxes(boxes, class_scores, cof_threshold, nms_area_threshold, indices);\n\n    // -------- Visualize the detection results -----------\n    cv::Mat rgb_mask = cv::Mat::zeros(src.size(), src.type());\n    cv::Mat masked_img;\n    cv::RNG rng;\n\n    Mat dst_temp = src.clone();\n    for (size_t i = 0; i < indices.size(); i++) \n    {\n        // Visualize the objects\n        int index = indices[i];\n        int class_id = class_ids[index];\n        rectangle(dst_temp, boxes[index], colors_seg[class_id % 16], 2, 8);\n        std::string label = class_names[class_id] + ":" + std::to_string(class_scores[index]).substr(0, 4);\n        Size textSize = cv::getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, 0);\n        Rect textBox(boxes[index].tl().x, boxes[index].tl().y - 15, textSize.width, textSize.height + 5);\n        cv::rectangle(dst_temp, textBox, colors_seg[class_id % 16], FILLED);\n        putText(dst_temp, label, Point(boxes[index].tl().x, boxes[index].tl().y - 5), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(255, 255, 255));\n\n        // Visualize the Masks\n        Mat m = mask_confs[i] * proto;\n        for (int col = 0; col < m.cols; col++) {\n            sigmoid_function(m.at<float>(0, col), m.at<float>(0, col));\n        }\n        cv::Mat m1 = m.reshape(1, 160); // 1x25600 -> 160x160\n        int x1 = std::max(0, boxes[index].x);\n        int y1 = std::max(0, boxes[index].y);\n        int x2 = std::max(0, boxes[index].br().x);\n        int y2 = std::max(0, boxes[index].br().y);\n        int mx1 = int(x1 / scale * 0.25);\n        int my1 = int(y1 / scale * 0.25);\n        int mx2 = int(x2 / scale * 0.25);\n        int my2 = int(y2 / scale * 0.25);\n\n        cv::Mat mask_roi = m1(cv::Range(my1, my2), cv::Range(mx1, mx2));\n        cv::Mat rm, det_mask;\n        cv::resize(mask_roi, rm, cv::Size(x2 - x1, y2 - y1));\n\n        for (int r = 0; r < rm.rows; r++) {\n            for (int c = 0; c < rm.cols; c++) {\n                float pv = rm.at<float>(r, c);\n                if (pv > 0.5) {\n                    rm.at<float>(r, c) = 1.0;\n                }\n                else {\n                    rm.at<float>(r, c) = 0.0;\n                }\n            }\n        }\n        rm = rm * rng.uniform(0, 255);\n        rm.convertTo(det_mask, CV_8UC1);\n        if ((y1 + det_mask.rows) >= dst_temp.rows) {\n            y2 = dst_temp.rows - 1;\n        }\n        if ((x1 + det_mask.cols) >= dst_temp.cols) {\n            x2 = dst_temp.cols - 1;\n        }\n\n        cv::Mat mask = cv::Mat::zeros(cv::Size(dst_temp.cols, dst_temp.rows), CV_8UC1);\n        det_mask(cv::Range(0, y2 - y1), cv::Range(0, x2 - x1)).copyTo(mask(cv::Range(y1, y2), cv::Range(x1, x2)));\n        add(rgb_mask, cv::Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255)), rgb_mask, mask);\n        addWeighted(dst_temp, 0.5, rgb_mask, 0.5, 0, masked_img);\n    }\n    dst = masked_img.clone();\n\n    return true;\n}\n\n// =====================姿态========================//\nbool YoloModel::LoadPoseModel(const string& xmlName, string& device)\n{\n    //待优化，如何把初始化部分进行提取出来\n   // -------- Step 1. Initialize OpenVINO Runtime Core --------\n    ov::Core core;\n\n    // -------- Step 2. Compile the Model --------\n    compiled_model_Pose = core.compile_model(xmlName, device);\n\n    // -------- Step 3. Create an Inference Request --------\n    infer_request_Pose = compiled_model_Pose.create_infer_request();\n\n    return true;\n}\n\nbool YoloModel::YoloPoseInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj)\n{\n    // -------- Step 4.Read a picture file and do the preprocess --------\n    // Preprocess the image\n    Mat letterbox_img;\n    letterbox(src, letterbox_img);\n    float scale = letterbox_img.size[0] / 640.0;\n    Mat blob = blobFromImage(letterbox_img, 1.0 / 255.0, Size(640, 640), Scalar(), true);\n\n    // -------- Step 5. Feed the blob into the input node of the Model -------\n    // Get input port for model with one input\n    auto input_port = compiled_model_Pose.input();\n    // Create tensor from external memory\n    ov::Tensor input_tensor(input_port.get_element_type(), input_port.get_shape(), blob.ptr(0));\n    // Set input tensor for model with one input\n    infer_request_Pose.set_input_tensor(input_tensor);\n\n    // -------- Step 6. Start inference --------\n    infer_request_Pose.infer();\n\n    // -------- Step 7. Get the inference result --------\n    auto output = infer_request_Pose.get_output_tensor(0);\n    auto output_shape = output.get_shape();\n    std::cout << "The shape of output tensor:" << output_shape << std::endl;\n\n    // -------- Step 8. Postprocess the result --------\n    float* data = output.data<float>();\n    Mat output_buffer(output_shape[1], output_shape[2], CV_32F, data);\n    transpose(output_buffer, output_buffer); //[8400,56]\n    std::vector<int> class_ids;\n    std::vector<float> class_scores;\n    std::vector<Rect> boxes;\n    std::vector<std::vector<float>> objects_keypoints;\n\n    // //56: box[cx, cy, w, h] + Score + [17,3] keypoints\n    for (int i = 0; i < output_buffer.rows; i++) {\n        float class_score = output_buffer.at<float>(i, 4);\n\n        if (class_score > cof_threshold) {\n            class_scores.push_back(class_score);\n            class_ids.push_back(0); //{0:"person"}\n            float cx = output_buffer.at<float>(i, 0);\n            float cy = output_buffer.at<float>(i, 1);\n            float w = output_buffer.at<float>(i, 2);\n            float h = output_buffer.at<float>(i, 3);\n            // Get the box\n            int left = int((cx - 0.5 * w) * scale);\n            int top = int((cy - 0.5 * h) * scale);\n            int width = int(w * scale);\n            int height = int(h * scale);\n            // Get the keypoints\n            std::vector<float> keypoints;\n            Mat kpts = output_buffer.row(i).colRange(5, 56);\n            for (int i = 0; i < 17; i++) {\n                float x = kpts.at<float>(0, i * 3 + 0) * scale;\n                float y = kpts.at<float>(0, i * 3 + 1) * scale;\n                float s = kpts.at<float>(0, i * 3 + 2);\n                keypoints.push_back(x);\n                keypoints.push_back(y);\n                keypoints.push_back(s);\n            }\n\n            boxes.push_back(Rect(left, top, width, height));\n            objects_keypoints.push_back(keypoints);\n        }\n    }\n    //NMS\n    std::vector<int> indices;\n    NMSBoxes(boxes, class_scores, cof_threshold, nms_area_threshold, indices);\n\n    dst = src.clone();\n    // -------- Visualize the detection results -----------\n    for (size_t i = 0; i < indices.size(); i++) {\n        int index = indices[i];\n        // Draw bounding box\n        rectangle(dst, boxes[index], Scalar(0, 0, 255), 2, 8);\n        std::string label = "Person:" + std::to_string(class_scores[index]).substr(0, 4);\n        Size textSize = cv::getTextSize(label, FONT_HERSHEY_SIMPLEX, 0.5, 1, 0);\n        Rect textBox(boxes[index].tl().x, boxes[index].tl().y - 15, textSize.width, textSize.height + 5);\n        cv::rectangle(dst, textBox, Scalar(0, 0, 255), FILLED);\n        putText(dst, label, Point(boxes[index].tl().x, boxes[index].tl().y - 5), FONT_HERSHEY_SIMPLEX, 0.5, Scalar(255, 255, 255));\n        // Draw keypoints\n        //std::vector<float> object_keypoints = objects_keypoints[index];\n        //for (int i = 0; i < 17; i++)\n        //{\n        //    int x = std::clamp(int(object_keypoints[i * 3 + 0]), 0, dst.cols);\n        //    int y = std::clamp(int(object_keypoints[i * 3 + 1]), 0, dst.rows);\n        //    //Draw point\n        //    circle(dst, Point(x, y), 5, posePalette[i], -1);\n        //}\n        // Draw keypoints-line\n    }\n    cv::Size shape = dst.size();\n    plot_keypoints(dst, objects_keypoints, shape);\n    return true;\n}\n\nvoid YoloModel::letterbox(const cv::Mat& source, cv::Mat& result)\n{\n    int col = source.cols;\n    int row = source.rows;\n    int _max = MAX(col, row);\n    result = Mat::zeros(_max, _max, CV_8UC3);\n    source.copyTo(result(Rect(0, 0, col, row)));\n}\n\nvoid YoloModel::sigmoid_function(float a, float& b) \n{\n    b = 1. / (1. + exp(-a));\n}\n\nvoid YoloModel::plot_keypoints(cv::Mat& image, const std::vector<std::vector<float>>& keypoints, const cv::Size& shape)\n{\n\n    int radius = 5;\n    bool drawLines = true;\n\n    if (keypoints.empty()) {\n        return;\n    }\n\n    std::vector<cv::Scalar> limbColorPalette;\n    std::vector<cv::Scalar> kptColorPalette;\n\n    for (int index : limbColorIndices) {\n        limbColorPalette.push_back(posePalette[index]);\n    }\n\n    for (int index : kptColorIndices) {\n        kptColorPalette.push_back(posePalette[index]);\n    }\n\n    for (const auto& keypoint : keypoints) {\n        bool isPose = keypoint.size() == 51;  // numKeypoints == 17 && keypoints[0].size() == 3;\n        drawLines &= isPose;\n\n        // draw points\n        for (int i = 0; i < 17; i++) {\n            int idx = i * 3;\n            int x_coord = static_cast<int>(keypoint[idx]);\n            int y_coord = static_cast<int>(keypoint[idx + 1]);\n\n            if (x_coord % shape.width != 0 && y_coord % shape.height != 0) {\n                if (keypoint.size() == 3) {\n                    float conf = keypoint[2];\n                    if (conf < 0.5) {\n                        continue;\n                    }\n                }\n                cv::Scalar color_k = isPose ? kptColorPalette[i] : cv::Scalar(0, 0,\n                    255);  // Default to red if not in pose mode\n                cv::circle(image, cv::Point(x_coord, y_coord), radius, color_k, -1, cv::LINE_AA);\n            }\n        }\n        // draw lines\n        if (drawLines) {\n            for (int i = 0; i < skeleton.size(); i++) {\n                const std::vector<int>& sk = skeleton[i];\n                int idx1 = sk[0] - 1;\n                int idx2 = sk[1] - 1;\n\n                int idx1_x_pos = idx1 * 3;\n                int idx2_x_pos = idx2 * 3;\n\n                int x1 = static_cast<int>(keypoint[idx1_x_pos]);\n                int y1 = static_cast<int>(keypoint[idx1_x_pos + 1]);\n                int x2 = static_cast<int>(keypoint[idx2_x_pos]);\n                int y2 = static_cast<int>(keypoint[idx2_x_pos + 1]);\n\n                float conf1 = keypoint[idx1_x_pos + 2];\n                float conf2 = keypoint[idx2_x_pos + 2];\n\n                // Check confidence thresholds\n                if (conf1 < 0.5 || conf2 < 0.5) {\n                    continue;\n                }\n\n                // Check if positions are within bounds\n                if (x1 % shape.width == 0 || y1 % shape.height == 0 || x1 < 0 || y1 < 0 ||\n                    x2 % shape.width == 0 || y2 % shape.height == 0 || x2 < 0 || y2 < 0) {\n                    continue;\n                }\n\n                // Draw a line between keypoints\n                cv::Scalar color_limb = limbColorPalette[i];\n                cv::line(image, cv::Point(x1, y1), cv::Point(x2, y2), color_limb, 2, cv::LINE_AA);\n            }\n        }\n    }\n}\n\n')])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br"),n("span",{staticClass:"line-number"},[s._v("75")]),n("br"),n("span",{staticClass:"line-number"},[s._v("76")]),n("br"),n("span",{staticClass:"line-number"},[s._v("77")]),n("br"),n("span",{staticClass:"line-number"},[s._v("78")]),n("br"),n("span",{staticClass:"line-number"},[s._v("79")]),n("br"),n("span",{staticClass:"line-number"},[s._v("80")]),n("br"),n("span",{staticClass:"line-number"},[s._v("81")]),n("br"),n("span",{staticClass:"line-number"},[s._v("82")]),n("br"),n("span",{staticClass:"line-number"},[s._v("83")]),n("br"),n("span",{staticClass:"line-number"},[s._v("84")]),n("br"),n("span",{staticClass:"line-number"},[s._v("85")]),n("br"),n("span",{staticClass:"line-number"},[s._v("86")]),n("br"),n("span",{staticClass:"line-number"},[s._v("87")]),n("br"),n("span",{staticClass:"line-number"},[s._v("88")]),n("br"),n("span",{staticClass:"line-number"},[s._v("89")]),n("br"),n("span",{staticClass:"line-number"},[s._v("90")]),n("br"),n("span",{staticClass:"line-number"},[s._v("91")]),n("br"),n("span",{staticClass:"line-number"},[s._v("92")]),n("br"),n("span",{staticClass:"line-number"},[s._v("93")]),n("br"),n("span",{staticClass:"line-number"},[s._v("94")]),n("br"),n("span",{staticClass:"line-number"},[s._v("95")]),n("br"),n("span",{staticClass:"line-number"},[s._v("96")]),n("br"),n("span",{staticClass:"line-number"},[s._v("97")]),n("br"),n("span",{staticClass:"line-number"},[s._v("98")]),n("br"),n("span",{staticClass:"line-number"},[s._v("99")]),n("br"),n("span",{staticClass:"line-number"},[s._v("100")]),n("br"),n("span",{staticClass:"line-number"},[s._v("101")]),n("br"),n("span",{staticClass:"line-number"},[s._v("102")]),n("br"),n("span",{staticClass:"line-number"},[s._v("103")]),n("br"),n("span",{staticClass:"line-number"},[s._v("104")]),n("br"),n("span",{staticClass:"line-number"},[s._v("105")]),n("br"),n("span",{staticClass:"line-number"},[s._v("106")]),n("br"),n("span",{staticClass:"line-number"},[s._v("107")]),n("br"),n("span",{staticClass:"line-number"},[s._v("108")]),n("br"),n("span",{staticClass:"line-number"},[s._v("109")]),n("br"),n("span",{staticClass:"line-number"},[s._v("110")]),n("br"),n("span",{staticClass:"line-number"},[s._v("111")]),n("br"),n("span",{staticClass:"line-number"},[s._v("112")]),n("br"),n("span",{staticClass:"line-number"},[s._v("113")]),n("br"),n("span",{staticClass:"line-number"},[s._v("114")]),n("br"),n("span",{staticClass:"line-number"},[s._v("115")]),n("br"),n("span",{staticClass:"line-number"},[s._v("116")]),n("br"),n("span",{staticClass:"line-number"},[s._v("117")]),n("br"),n("span",{staticClass:"line-number"},[s._v("118")]),n("br"),n("span",{staticClass:"line-number"},[s._v("119")]),n("br"),n("span",{staticClass:"line-number"},[s._v("120")]),n("br"),n("span",{staticClass:"line-number"},[s._v("121")]),n("br"),n("span",{staticClass:"line-number"},[s._v("122")]),n("br"),n("span",{staticClass:"line-number"},[s._v("123")]),n("br"),n("span",{staticClass:"line-number"},[s._v("124")]),n("br"),n("span",{staticClass:"line-number"},[s._v("125")]),n("br"),n("span",{staticClass:"line-number"},[s._v("126")]),n("br"),n("span",{staticClass:"line-number"},[s._v("127")]),n("br"),n("span",{staticClass:"line-number"},[s._v("128")]),n("br"),n("span",{staticClass:"line-number"},[s._v("129")]),n("br"),n("span",{staticClass:"line-number"},[s._v("130")]),n("br"),n("span",{staticClass:"line-number"},[s._v("131")]),n("br"),n("span",{staticClass:"line-number"},[s._v("132")]),n("br"),n("span",{staticClass:"line-number"},[s._v("133")]),n("br"),n("span",{staticClass:"line-number"},[s._v("134")]),n("br"),n("span",{staticClass:"line-number"},[s._v("135")]),n("br"),n("span",{staticClass:"line-number"},[s._v("136")]),n("br"),n("span",{staticClass:"line-number"},[s._v("137")]),n("br"),n("span",{staticClass:"line-number"},[s._v("138")]),n("br"),n("span",{staticClass:"line-number"},[s._v("139")]),n("br"),n("span",{staticClass:"line-number"},[s._v("140")]),n("br"),n("span",{staticClass:"line-number"},[s._v("141")]),n("br"),n("span",{staticClass:"line-number"},[s._v("142")]),n("br"),n("span",{staticClass:"line-number"},[s._v("143")]),n("br"),n("span",{staticClass:"line-number"},[s._v("144")]),n("br"),n("span",{staticClass:"line-number"},[s._v("145")]),n("br"),n("span",{staticClass:"line-number"},[s._v("146")]),n("br"),n("span",{staticClass:"line-number"},[s._v("147")]),n("br"),n("span",{staticClass:"line-number"},[s._v("148")]),n("br"),n("span",{staticClass:"line-number"},[s._v("149")]),n("br"),n("span",{staticClass:"line-number"},[s._v("150")]),n("br"),n("span",{staticClass:"line-number"},[s._v("151")]),n("br"),n("span",{staticClass:"line-number"},[s._v("152")]),n("br"),n("span",{staticClass:"line-number"},[s._v("153")]),n("br"),n("span",{staticClass:"line-number"},[s._v("154")]),n("br"),n("span",{staticClass:"line-number"},[s._v("155")]),n("br"),n("span",{staticClass:"line-number"},[s._v("156")]),n("br"),n("span",{staticClass:"line-number"},[s._v("157")]),n("br"),n("span",{staticClass:"line-number"},[s._v("158")]),n("br"),n("span",{staticClass:"line-number"},[s._v("159")]),n("br"),n("span",{staticClass:"line-number"},[s._v("160")]),n("br"),n("span",{staticClass:"line-number"},[s._v("161")]),n("br"),n("span",{staticClass:"line-number"},[s._v("162")]),n("br"),n("span",{staticClass:"line-number"},[s._v("163")]),n("br"),n("span",{staticClass:"line-number"},[s._v("164")]),n("br"),n("span",{staticClass:"line-number"},[s._v("165")]),n("br"),n("span",{staticClass:"line-number"},[s._v("166")]),n("br"),n("span",{staticClass:"line-number"},[s._v("167")]),n("br"),n("span",{staticClass:"line-number"},[s._v("168")]),n("br"),n("span",{staticClass:"line-number"},[s._v("169")]),n("br"),n("span",{staticClass:"line-number"},[s._v("170")]),n("br"),n("span",{staticClass:"line-number"},[s._v("171")]),n("br"),n("span",{staticClass:"line-number"},[s._v("172")]),n("br"),n("span",{staticClass:"line-number"},[s._v("173")]),n("br"),n("span",{staticClass:"line-number"},[s._v("174")]),n("br"),n("span",{staticClass:"line-number"},[s._v("175")]),n("br"),n("span",{staticClass:"line-number"},[s._v("176")]),n("br"),n("span",{staticClass:"line-number"},[s._v("177")]),n("br"),n("span",{staticClass:"line-number"},[s._v("178")]),n("br"),n("span",{staticClass:"line-number"},[s._v("179")]),n("br"),n("span",{staticClass:"line-number"},[s._v("180")]),n("br"),n("span",{staticClass:"line-number"},[s._v("181")]),n("br"),n("span",{staticClass:"line-number"},[s._v("182")]),n("br"),n("span",{staticClass:"line-number"},[s._v("183")]),n("br"),n("span",{staticClass:"line-number"},[s._v("184")]),n("br"),n("span",{staticClass:"line-number"},[s._v("185")]),n("br"),n("span",{staticClass:"line-number"},[s._v("186")]),n("br"),n("span",{staticClass:"line-number"},[s._v("187")]),n("br"),n("span",{staticClass:"line-number"},[s._v("188")]),n("br"),n("span",{staticClass:"line-number"},[s._v("189")]),n("br"),n("span",{staticClass:"line-number"},[s._v("190")]),n("br"),n("span",{staticClass:"line-number"},[s._v("191")]),n("br"),n("span",{staticClass:"line-number"},[s._v("192")]),n("br"),n("span",{staticClass:"line-number"},[s._v("193")]),n("br"),n("span",{staticClass:"line-number"},[s._v("194")]),n("br"),n("span",{staticClass:"line-number"},[s._v("195")]),n("br"),n("span",{staticClass:"line-number"},[s._v("196")]),n("br"),n("span",{staticClass:"line-number"},[s._v("197")]),n("br"),n("span",{staticClass:"line-number"},[s._v("198")]),n("br"),n("span",{staticClass:"line-number"},[s._v("199")]),n("br"),n("span",{staticClass:"line-number"},[s._v("200")]),n("br"),n("span",{staticClass:"line-number"},[s._v("201")]),n("br"),n("span",{staticClass:"line-number"},[s._v("202")]),n("br"),n("span",{staticClass:"line-number"},[s._v("203")]),n("br"),n("span",{staticClass:"line-number"},[s._v("204")]),n("br"),n("span",{staticClass:"line-number"},[s._v("205")]),n("br"),n("span",{staticClass:"line-number"},[s._v("206")]),n("br"),n("span",{staticClass:"line-number"},[s._v("207")]),n("br"),n("span",{staticClass:"line-number"},[s._v("208")]),n("br"),n("span",{staticClass:"line-number"},[s._v("209")]),n("br"),n("span",{staticClass:"line-number"},[s._v("210")]),n("br"),n("span",{staticClass:"line-number"},[s._v("211")]),n("br"),n("span",{staticClass:"line-number"},[s._v("212")]),n("br"),n("span",{staticClass:"line-number"},[s._v("213")]),n("br"),n("span",{staticClass:"line-number"},[s._v("214")]),n("br"),n("span",{staticClass:"line-number"},[s._v("215")]),n("br"),n("span",{staticClass:"line-number"},[s._v("216")]),n("br"),n("span",{staticClass:"line-number"},[s._v("217")]),n("br"),n("span",{staticClass:"line-number"},[s._v("218")]),n("br"),n("span",{staticClass:"line-number"},[s._v("219")]),n("br"),n("span",{staticClass:"line-number"},[s._v("220")]),n("br"),n("span",{staticClass:"line-number"},[s._v("221")]),n("br"),n("span",{staticClass:"line-number"},[s._v("222")]),n("br"),n("span",{staticClass:"line-number"},[s._v("223")]),n("br"),n("span",{staticClass:"line-number"},[s._v("224")]),n("br"),n("span",{staticClass:"line-number"},[s._v("225")]),n("br"),n("span",{staticClass:"line-number"},[s._v("226")]),n("br"),n("span",{staticClass:"line-number"},[s._v("227")]),n("br"),n("span",{staticClass:"line-number"},[s._v("228")]),n("br"),n("span",{staticClass:"line-number"},[s._v("229")]),n("br"),n("span",{staticClass:"line-number"},[s._v("230")]),n("br"),n("span",{staticClass:"line-number"},[s._v("231")]),n("br"),n("span",{staticClass:"line-number"},[s._v("232")]),n("br"),n("span",{staticClass:"line-number"},[s._v("233")]),n("br"),n("span",{staticClass:"line-number"},[s._v("234")]),n("br"),n("span",{staticClass:"line-number"},[s._v("235")]),n("br"),n("span",{staticClass:"line-number"},[s._v("236")]),n("br"),n("span",{staticClass:"line-number"},[s._v("237")]),n("br"),n("span",{staticClass:"line-number"},[s._v("238")]),n("br"),n("span",{staticClass:"line-number"},[s._v("239")]),n("br"),n("span",{staticClass:"line-number"},[s._v("240")]),n("br"),n("span",{staticClass:"line-number"},[s._v("241")]),n("br"),n("span",{staticClass:"line-number"},[s._v("242")]),n("br"),n("span",{staticClass:"line-number"},[s._v("243")]),n("br"),n("span",{staticClass:"line-number"},[s._v("244")]),n("br"),n("span",{staticClass:"line-number"},[s._v("245")]),n("br"),n("span",{staticClass:"line-number"},[s._v("246")]),n("br"),n("span",{staticClass:"line-number"},[s._v("247")]),n("br"),n("span",{staticClass:"line-number"},[s._v("248")]),n("br"),n("span",{staticClass:"line-number"},[s._v("249")]),n("br"),n("span",{staticClass:"line-number"},[s._v("250")]),n("br"),n("span",{staticClass:"line-number"},[s._v("251")]),n("br"),n("span",{staticClass:"line-number"},[s._v("252")]),n("br"),n("span",{staticClass:"line-number"},[s._v("253")]),n("br"),n("span",{staticClass:"line-number"},[s._v("254")]),n("br"),n("span",{staticClass:"line-number"},[s._v("255")]),n("br"),n("span",{staticClass:"line-number"},[s._v("256")]),n("br"),n("span",{staticClass:"line-number"},[s._v("257")]),n("br"),n("span",{staticClass:"line-number"},[s._v("258")]),n("br"),n("span",{staticClass:"line-number"},[s._v("259")]),n("br"),n("span",{staticClass:"line-number"},[s._v("260")]),n("br"),n("span",{staticClass:"line-number"},[s._v("261")]),n("br"),n("span",{staticClass:"line-number"},[s._v("262")]),n("br"),n("span",{staticClass:"line-number"},[s._v("263")]),n("br"),n("span",{staticClass:"line-number"},[s._v("264")]),n("br"),n("span",{staticClass:"line-number"},[s._v("265")]),n("br"),n("span",{staticClass:"line-number"},[s._v("266")]),n("br"),n("span",{staticClass:"line-number"},[s._v("267")]),n("br"),n("span",{staticClass:"line-number"},[s._v("268")]),n("br"),n("span",{staticClass:"line-number"},[s._v("269")]),n("br"),n("span",{staticClass:"line-number"},[s._v("270")]),n("br"),n("span",{staticClass:"line-number"},[s._v("271")]),n("br"),n("span",{staticClass:"line-number"},[s._v("272")]),n("br"),n("span",{staticClass:"line-number"},[s._v("273")]),n("br"),n("span",{staticClass:"line-number"},[s._v("274")]),n("br"),n("span",{staticClass:"line-number"},[s._v("275")]),n("br"),n("span",{staticClass:"line-number"},[s._v("276")]),n("br"),n("span",{staticClass:"line-number"},[s._v("277")]),n("br"),n("span",{staticClass:"line-number"},[s._v("278")]),n("br"),n("span",{staticClass:"line-number"},[s._v("279")]),n("br"),n("span",{staticClass:"line-number"},[s._v("280")]),n("br"),n("span",{staticClass:"line-number"},[s._v("281")]),n("br"),n("span",{staticClass:"line-number"},[s._v("282")]),n("br"),n("span",{staticClass:"line-number"},[s._v("283")]),n("br"),n("span",{staticClass:"line-number"},[s._v("284")]),n("br"),n("span",{staticClass:"line-number"},[s._v("285")]),n("br"),n("span",{staticClass:"line-number"},[s._v("286")]),n("br"),n("span",{staticClass:"line-number"},[s._v("287")]),n("br"),n("span",{staticClass:"line-number"},[s._v("288")]),n("br"),n("span",{staticClass:"line-number"},[s._v("289")]),n("br"),n("span",{staticClass:"line-number"},[s._v("290")]),n("br"),n("span",{staticClass:"line-number"},[s._v("291")]),n("br"),n("span",{staticClass:"line-number"},[s._v("292")]),n("br"),n("span",{staticClass:"line-number"},[s._v("293")]),n("br"),n("span",{staticClass:"line-number"},[s._v("294")]),n("br"),n("span",{staticClass:"line-number"},[s._v("295")]),n("br"),n("span",{staticClass:"line-number"},[s._v("296")]),n("br"),n("span",{staticClass:"line-number"},[s._v("297")]),n("br"),n("span",{staticClass:"line-number"},[s._v("298")]),n("br"),n("span",{staticClass:"line-number"},[s._v("299")]),n("br"),n("span",{staticClass:"line-number"},[s._v("300")]),n("br"),n("span",{staticClass:"line-number"},[s._v("301")]),n("br"),n("span",{staticClass:"line-number"},[s._v("302")]),n("br"),n("span",{staticClass:"line-number"},[s._v("303")]),n("br"),n("span",{staticClass:"line-number"},[s._v("304")]),n("br"),n("span",{staticClass:"line-number"},[s._v("305")]),n("br"),n("span",{staticClass:"line-number"},[s._v("306")]),n("br"),n("span",{staticClass:"line-number"},[s._v("307")]),n("br"),n("span",{staticClass:"line-number"},[s._v("308")]),n("br"),n("span",{staticClass:"line-number"},[s._v("309")]),n("br"),n("span",{staticClass:"line-number"},[s._v("310")]),n("br"),n("span",{staticClass:"line-number"},[s._v("311")]),n("br"),n("span",{staticClass:"line-number"},[s._v("312")]),n("br"),n("span",{staticClass:"line-number"},[s._v("313")]),n("br"),n("span",{staticClass:"line-number"},[s._v("314")]),n("br"),n("span",{staticClass:"line-number"},[s._v("315")]),n("br"),n("span",{staticClass:"line-number"},[s._v("316")]),n("br"),n("span",{staticClass:"line-number"},[s._v("317")]),n("br"),n("span",{staticClass:"line-number"},[s._v("318")]),n("br"),n("span",{staticClass:"line-number"},[s._v("319")]),n("br"),n("span",{staticClass:"line-number"},[s._v("320")]),n("br"),n("span",{staticClass:"line-number"},[s._v("321")]),n("br"),n("span",{staticClass:"line-number"},[s._v("322")]),n("br"),n("span",{staticClass:"line-number"},[s._v("323")]),n("br"),n("span",{staticClass:"line-number"},[s._v("324")]),n("br"),n("span",{staticClass:"line-number"},[s._v("325")]),n("br"),n("span",{staticClass:"line-number"},[s._v("326")]),n("br"),n("span",{staticClass:"line-number"},[s._v("327")]),n("br"),n("span",{staticClass:"line-number"},[s._v("328")]),n("br"),n("span",{staticClass:"line-number"},[s._v("329")]),n("br"),n("span",{staticClass:"line-number"},[s._v("330")]),n("br"),n("span",{staticClass:"line-number"},[s._v("331")]),n("br"),n("span",{staticClass:"line-number"},[s._v("332")]),n("br"),n("span",{staticClass:"line-number"},[s._v("333")]),n("br"),n("span",{staticClass:"line-number"},[s._v("334")]),n("br"),n("span",{staticClass:"line-number"},[s._v("335")]),n("br"),n("span",{staticClass:"line-number"},[s._v("336")]),n("br"),n("span",{staticClass:"line-number"},[s._v("337")]),n("br"),n("span",{staticClass:"line-number"},[s._v("338")]),n("br"),n("span",{staticClass:"line-number"},[s._v("339")]),n("br"),n("span",{staticClass:"line-number"},[s._v("340")]),n("br"),n("span",{staticClass:"line-number"},[s._v("341")]),n("br"),n("span",{staticClass:"line-number"},[s._v("342")]),n("br"),n("span",{staticClass:"line-number"},[s._v("343")]),n("br"),n("span",{staticClass:"line-number"},[s._v("344")]),n("br"),n("span",{staticClass:"line-number"},[s._v("345")]),n("br"),n("span",{staticClass:"line-number"},[s._v("346")]),n("br"),n("span",{staticClass:"line-number"},[s._v("347")]),n("br"),n("span",{staticClass:"line-number"},[s._v("348")]),n("br"),n("span",{staticClass:"line-number"},[s._v("349")]),n("br"),n("span",{staticClass:"line-number"},[s._v("350")]),n("br"),n("span",{staticClass:"line-number"},[s._v("351")]),n("br"),n("span",{staticClass:"line-number"},[s._v("352")]),n("br"),n("span",{staticClass:"line-number"},[s._v("353")]),n("br"),n("span",{staticClass:"line-number"},[s._v("354")]),n("br"),n("span",{staticClass:"line-number"},[s._v("355")]),n("br"),n("span",{staticClass:"line-number"},[s._v("356")]),n("br"),n("span",{staticClass:"line-number"},[s._v("357")]),n("br"),n("span",{staticClass:"line-number"},[s._v("358")]),n("br"),n("span",{staticClass:"line-number"},[s._v("359")]),n("br"),n("span",{staticClass:"line-number"},[s._v("360")]),n("br"),n("span",{staticClass:"line-number"},[s._v("361")]),n("br"),n("span",{staticClass:"line-number"},[s._v("362")]),n("br"),n("span",{staticClass:"line-number"},[s._v("363")]),n("br"),n("span",{staticClass:"line-number"},[s._v("364")]),n("br"),n("span",{staticClass:"line-number"},[s._v("365")]),n("br"),n("span",{staticClass:"line-number"},[s._v("366")]),n("br"),n("span",{staticClass:"line-number"},[s._v("367")]),n("br"),n("span",{staticClass:"line-number"},[s._v("368")]),n("br"),n("span",{staticClass:"line-number"},[s._v("369")]),n("br"),n("span",{staticClass:"line-number"},[s._v("370")]),n("br"),n("span",{staticClass:"line-number"},[s._v("371")]),n("br"),n("span",{staticClass:"line-number"},[s._v("372")]),n("br"),n("span",{staticClass:"line-number"},[s._v("373")]),n("br"),n("span",{staticClass:"line-number"},[s._v("374")]),n("br"),n("span",{staticClass:"line-number"},[s._v("375")]),n("br"),n("span",{staticClass:"line-number"},[s._v("376")]),n("br"),n("span",{staticClass:"line-number"},[s._v("377")]),n("br"),n("span",{staticClass:"line-number"},[s._v("378")]),n("br"),n("span",{staticClass:"line-number"},[s._v("379")]),n("br"),n("span",{staticClass:"line-number"},[s._v("380")]),n("br"),n("span",{staticClass:"line-number"},[s._v("381")]),n("br"),n("span",{staticClass:"line-number"},[s._v("382")]),n("br"),n("span",{staticClass:"line-number"},[s._v("383")]),n("br"),n("span",{staticClass:"line-number"},[s._v("384")]),n("br"),n("span",{staticClass:"line-number"},[s._v("385")]),n("br"),n("span",{staticClass:"line-number"},[s._v("386")]),n("br"),n("span",{staticClass:"line-number"},[s._v("387")]),n("br"),n("span",{staticClass:"line-number"},[s._v("388")]),n("br"),n("span",{staticClass:"line-number"},[s._v("389")]),n("br"),n("span",{staticClass:"line-number"},[s._v("390")]),n("br"),n("span",{staticClass:"line-number"},[s._v("391")]),n("br"),n("span",{staticClass:"line-number"},[s._v("392")]),n("br"),n("span",{staticClass:"line-number"},[s._v("393")]),n("br"),n("span",{staticClass:"line-number"},[s._v("394")]),n("br"),n("span",{staticClass:"line-number"},[s._v("395")]),n("br"),n("span",{staticClass:"line-number"},[s._v("396")]),n("br"),n("span",{staticClass:"line-number"},[s._v("397")]),n("br"),n("span",{staticClass:"line-number"},[s._v("398")]),n("br"),n("span",{staticClass:"line-number"},[s._v("399")]),n("br"),n("span",{staticClass:"line-number"},[s._v("400")]),n("br"),n("span",{staticClass:"line-number"},[s._v("401")]),n("br"),n("span",{staticClass:"line-number"},[s._v("402")]),n("br"),n("span",{staticClass:"line-number"},[s._v("403")]),n("br"),n("span",{staticClass:"line-number"},[s._v("404")]),n("br"),n("span",{staticClass:"line-number"},[s._v("405")]),n("br"),n("span",{staticClass:"line-number"},[s._v("406")]),n("br"),n("span",{staticClass:"line-number"},[s._v("407")]),n("br"),n("span",{staticClass:"line-number"},[s._v("408")]),n("br"),n("span",{staticClass:"line-number"},[s._v("409")]),n("br"),n("span",{staticClass:"line-number"},[s._v("410")]),n("br"),n("span",{staticClass:"line-number"},[s._v("411")]),n("br"),n("span",{staticClass:"line-number"},[s._v("412")]),n("br"),n("span",{staticClass:"line-number"},[s._v("413")]),n("br"),n("span",{staticClass:"line-number"},[s._v("414")]),n("br"),n("span",{staticClass:"line-number"},[s._v("415")]),n("br"),n("span",{staticClass:"line-number"},[s._v("416")]),n("br"),n("span",{staticClass:"line-number"},[s._v("417")]),n("br"),n("span",{staticClass:"line-number"},[s._v("418")]),n("br"),n("span",{staticClass:"line-number"},[s._v("419")]),n("br"),n("span",{staticClass:"line-number"},[s._v("420")]),n("br"),n("span",{staticClass:"line-number"},[s._v("421")]),n("br"),n("span",{staticClass:"line-number"},[s._v("422")]),n("br"),n("span",{staticClass:"line-number"},[s._v("423")]),n("br"),n("span",{staticClass:"line-number"},[s._v("424")]),n("br"),n("span",{staticClass:"line-number"},[s._v("425")]),n("br"),n("span",{staticClass:"line-number"},[s._v("426")]),n("br"),n("span",{staticClass:"line-number"},[s._v("427")]),n("br"),n("span",{staticClass:"line-number"},[s._v("428")]),n("br"),n("span",{staticClass:"line-number"},[s._v("429")]),n("br"),n("span",{staticClass:"line-number"},[s._v("430")]),n("br"),n("span",{staticClass:"line-number"},[s._v("431")]),n("br"),n("span",{staticClass:"line-number"},[s._v("432")]),n("br"),n("span",{staticClass:"line-number"},[s._v("433")]),n("br"),n("span",{staticClass:"line-number"},[s._v("434")]),n("br"),n("span",{staticClass:"line-number"},[s._v("435")]),n("br"),n("span",{staticClass:"line-number"},[s._v("436")]),n("br"),n("span",{staticClass:"line-number"},[s._v("437")]),n("br"),n("span",{staticClass:"line-number"},[s._v("438")]),n("br"),n("span",{staticClass:"line-number"},[s._v("439")]),n("br"),n("span",{staticClass:"line-number"},[s._v("440")]),n("br"),n("span",{staticClass:"line-number"},[s._v("441")]),n("br"),n("span",{staticClass:"line-number"},[s._v("442")]),n("br"),n("span",{staticClass:"line-number"},[s._v("443")]),n("br"),n("span",{staticClass:"line-number"},[s._v("444")]),n("br"),n("span",{staticClass:"line-number"},[s._v("445")]),n("br"),n("span",{staticClass:"line-number"},[s._v("446")]),n("br"),n("span",{staticClass:"line-number"},[s._v("447")]),n("br"),n("span",{staticClass:"line-number"},[s._v("448")]),n("br"),n("span",{staticClass:"line-number"},[s._v("449")]),n("br"),n("span",{staticClass:"line-number"},[s._v("450")]),n("br"),n("span",{staticClass:"line-number"},[s._v("451")]),n("br"),n("span",{staticClass:"line-number"},[s._v("452")]),n("br"),n("span",{staticClass:"line-number"},[s._v("453")]),n("br"),n("span",{staticClass:"line-number"},[s._v("454")]),n("br"),n("span",{staticClass:"line-number"},[s._v("455")]),n("br"),n("span",{staticClass:"line-number"},[s._v("456")]),n("br"),n("span",{staticClass:"line-number"},[s._v("457")]),n("br"),n("span",{staticClass:"line-number"},[s._v("458")]),n("br"),n("span",{staticClass:"line-number"},[s._v("459")]),n("br"),n("span",{staticClass:"line-number"},[s._v("460")]),n("br"),n("span",{staticClass:"line-number"},[s._v("461")]),n("br"),n("span",{staticClass:"line-number"},[s._v("462")]),n("br"),n("span",{staticClass:"line-number"},[s._v("463")]),n("br"),n("span",{staticClass:"line-number"},[s._v("464")]),n("br"),n("span",{staticClass:"line-number"},[s._v("465")]),n("br"),n("span",{staticClass:"line-number"},[s._v("466")]),n("br"),n("span",{staticClass:"line-number"},[s._v("467")]),n("br"),n("span",{staticClass:"line-number"},[s._v("468")]),n("br"),n("span",{staticClass:"line-number"},[s._v("469")]),n("br"),n("span",{staticClass:"line-number"},[s._v("470")]),n("br"),n("span",{staticClass:"line-number"},[s._v("471")]),n("br"),n("span",{staticClass:"line-number"},[s._v("472")]),n("br"),n("span",{staticClass:"line-number"},[s._v("473")]),n("br"),n("span",{staticClass:"line-number"},[s._v("474")]),n("br"),n("span",{staticClass:"line-number"},[s._v("475")]),n("br"),n("span",{staticClass:"line-number"},[s._v("476")]),n("br"),n("span",{staticClass:"line-number"},[s._v("477")]),n("br"),n("span",{staticClass:"line-number"},[s._v("478")]),n("br"),n("span",{staticClass:"line-number"},[s._v("479")]),n("br"),n("span",{staticClass:"line-number"},[s._v("480")]),n("br"),n("span",{staticClass:"line-number"},[s._v("481")]),n("br"),n("span",{staticClass:"line-number"},[s._v("482")]),n("br"),n("span",{staticClass:"line-number"},[s._v("483")]),n("br"),n("span",{staticClass:"line-number"},[s._v("484")]),n("br"),n("span",{staticClass:"line-number"},[s._v("485")]),n("br"),n("span",{staticClass:"line-number"},[s._v("486")]),n("br"),n("span",{staticClass:"line-number"},[s._v("487")]),n("br"),n("span",{staticClass:"line-number"},[s._v("488")]),n("br"),n("span",{staticClass:"line-number"},[s._v("489")]),n("br"),n("span",{staticClass:"line-number"},[s._v("490")]),n("br"),n("span",{staticClass:"line-number"},[s._v("491")]),n("br"),n("span",{staticClass:"line-number"},[s._v("492")]),n("br"),n("span",{staticClass:"line-number"},[s._v("493")]),n("br"),n("span",{staticClass:"line-number"},[s._v("494")]),n("br"),n("span",{staticClass:"line-number"},[s._v("495")]),n("br"),n("span",{staticClass:"line-number"},[s._v("496")]),n("br"),n("span",{staticClass:"line-number"},[s._v("497")]),n("br"),n("span",{staticClass:"line-number"},[s._v("498")]),n("br"),n("span",{staticClass:"line-number"},[s._v("499")]),n("br"),n("span",{staticClass:"line-number"},[s._v("500")]),n("br"),n("span",{staticClass:"line-number"},[s._v("501")]),n("br"),n("span",{staticClass:"line-number"},[s._v("502")]),n("br"),n("span",{staticClass:"line-number"},[s._v("503")]),n("br"),n("span",{staticClass:"line-number"},[s._v("504")]),n("br"),n("span",{staticClass:"line-number"},[s._v("505")]),n("br"),n("span",{staticClass:"line-number"},[s._v("506")]),n("br"),n("span",{staticClass:"line-number"},[s._v("507")]),n("br"),n("span",{staticClass:"line-number"},[s._v("508")]),n("br"),n("span",{staticClass:"line-number"},[s._v("509")]),n("br"),n("span",{staticClass:"line-number"},[s._v("510")]),n("br"),n("span",{staticClass:"line-number"},[s._v("511")]),n("br"),n("span",{staticClass:"line-number"},[s._v("512")]),n("br"),n("span",{staticClass:"line-number"},[s._v("513")]),n("br"),n("span",{staticClass:"line-number"},[s._v("514")]),n("br"),n("span",{staticClass:"line-number"},[s._v("515")]),n("br"),n("span",{staticClass:"line-number"},[s._v("516")]),n("br"),n("span",{staticClass:"line-number"},[s._v("517")]),n("br"),n("span",{staticClass:"line-number"},[s._v("518")]),n("br"),n("span",{staticClass:"line-number"},[s._v("519")]),n("br"),n("span",{staticClass:"line-number"},[s._v("520")]),n("br"),n("span",{staticClass:"line-number"},[s._v("521")]),n("br"),n("span",{staticClass:"line-number"},[s._v("522")]),n("br"),n("span",{staticClass:"line-number"},[s._v("523")]),n("br"),n("span",{staticClass:"line-number"},[s._v("524")]),n("br"),n("span",{staticClass:"line-number"},[s._v("525")]),n("br"),n("span",{staticClass:"line-number"},[s._v("526")]),n("br"),n("span",{staticClass:"line-number"},[s._v("527")]),n("br"),n("span",{staticClass:"line-number"},[s._v("528")]),n("br"),n("span",{staticClass:"line-number"},[s._v("529")]),n("br"),n("span",{staticClass:"line-number"},[s._v("530")]),n("br"),n("span",{staticClass:"line-number"},[s._v("531")]),n("br"),n("span",{staticClass:"line-number"},[s._v("532")]),n("br"),n("span",{staticClass:"line-number"},[s._v("533")]),n("br"),n("span",{staticClass:"line-number"},[s._v("534")]),n("br"),n("span",{staticClass:"line-number"},[s._v("535")]),n("br"),n("span",{staticClass:"line-number"},[s._v("536")]),n("br"),n("span",{staticClass:"line-number"},[s._v("537")]),n("br"),n("span",{staticClass:"line-number"},[s._v("538")]),n("br"),n("span",{staticClass:"line-number"},[s._v("539")]),n("br"),n("span",{staticClass:"line-number"},[s._v("540")]),n("br"),n("span",{staticClass:"line-number"},[s._v("541")]),n("br"),n("span",{staticClass:"line-number"},[s._v("542")]),n("br"),n("span",{staticClass:"line-number"},[s._v("543")]),n("br"),n("span",{staticClass:"line-number"},[s._v("544")]),n("br"),n("span",{staticClass:"line-number"},[s._v("545")]),n("br"),n("span",{staticClass:"line-number"},[s._v("546")]),n("br"),n("span",{staticClass:"line-number"},[s._v("547")]),n("br")])]),n("h3",{attrs:{id:"_1-2-ov-yolov8-h"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-ov-yolov8-h"}},[s._v("#")]),s._v(" 1.2 ov_yolov8.h")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v("#pragma once\n#ifdef OV_YOLOV8_EXPORTS\n#define OV_YOLOV8_API _declspec(dllexport)\n#else\n#define OV_YOLOV8_API _declspec(dllimport)\n#endif\n#include <iostream>\n#include <string>\n#include <vector>\n#include <algorithm>\n#include <random>\n#include <openvino/openvino.hpp> //openvino header file\n#include <opencv2/opencv.hpp>    //opencv header file\nusing namespace cv;\nusing namespace std;\nusing namespace dnn;\n\n// 定义输出结构体\ntypedef struct {\n    float prob;\n    cv::Rect rect;\n    int classid;\n}Object;\n\n//定义类\nclass OV_YOLOV8_API YoloModel\n{\npublic:\n    YoloModel();\n    ~YoloModel();\n    //检测\n    bool LoadDetectModel(const string& xmlName, string& device);\n    bool YoloDetectInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj);\n\n    //分类\n    bool YoloClsInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj);\n    bool LoadClsModel(const string& xmlName, string& device);\n\n    //分割\n    bool LoadSegModel(const string& xmlName, string& device);\n    bool YoloSegInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj);\n\n    //姿态\n    bool LoadPoseModel(const string& xmlName, string& device);\n    bool YoloPoseInfer(const Mat& src, double cof_threshold, double nms_area_threshold, Mat& dst, vector<Object>& vecObj);\n\nprivate:\n    ov::InferRequest infer_request_Detect;\n    ov::CompiledModel compiled_model_Detect;\n\n    ov::InferRequest infer_request_Cls;\n    ov::CompiledModel compiled_model_Detect_Cls;\n\n    ov::InferRequest infer_request_Seg;\n    ov::CompiledModel compiled_model_Seg;\n\n    ov::InferRequest infer_request_Pose;\n    ov::CompiledModel compiled_model_Pose;\n\n    //增加函数\n    // Keep the ratio before resize\n    void letterbox(const Mat& source, Mat& result);\n    void sigmoid_function(float a, float& b);\n    void plot_keypoints(cv::Mat& image, const std::vector<std::vector<float>>& keypoints, const cv::Size& shape);\n};\n\n")])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br")])]),n("h2",{attrs:{id:"_2-batch-test"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-batch-test"}},[s._v("#")]),s._v(" 2.Batch_Test")]),s._v(" "),n("h3",{attrs:{id:"_2-1-batch-test-cpp"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-batch-test-cpp"}},[s._v("#")]),s._v(" 2.1 Batch_Test.cpp")]),s._v(" "),n("div",{staticClass:"language- line-numbers-mode"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[s._v('#include <iostream>\n#include "ov_yolov8.h"\n#pragma comment(lib,"..//x64//Release//OV_YOLOV8_DLL.lib")\n\nint main(int argc, char* argv[])\n{\n    YoloModel yolomodel;\n    string xmlName_Detect = "./yolov8/model/yolov8n.xml";\n    string xmlName_Cls = "./yolov8/model/yolov8n-cls.xml";\n    string xmlName_Seg = "./yolov8/model/yolov8n-seg.xml";\n    string xmlName_Pose = "./yolov8/model/yolov8n-Pose.xml";\n    string device = "GPU";\n    bool initDetectflag = yolomodel.LoadDetectModel(xmlName_Detect, device);\n    bool initClsflag = yolomodel.LoadClsModel(xmlName_Cls, device);\n    bool initSegflag = yolomodel.LoadSegModel(xmlName_Seg, device);\n    bool initPoseflag = yolomodel.LoadPoseModel(xmlName_Pose, device);\n    if (initDetectflag == true)\n    {\n        cout << "检测模型初始化成功" << endl;\n    }\n    if (initClsflag == true)\n    {\n        cout << "分类模型初始化成功" << endl;\n    }\n    if (initSegflag == true)\n    {\n        cout << "分割模型初始化成功" << endl;\n    }\n    if (initPoseflag == true)\n    {\n        cout << "姿态模型初始化成功" << endl;\n    }\n    // 读取图像\n    Mat img_Detect = cv::imread("./yolov8/img/bus.jpg");\n    Mat img_Cls = img_Detect.clone();\n    Mat img_Seg = img_Detect.clone();\n    Mat img_Pose = img_Detect.clone();\n\n    // 检测推理\n    Mat dst_detect;\n    double cof_threshold_detect  = 0.25;\n    double nms_area_threshold_detect = 0.5;\n    vector<Object> vecObj = {};\n    bool InferDetectflag = yolomodel.YoloDetectInfer(img_Detect, cof_threshold_detect, nms_area_threshold_detect, dst_detect, vecObj);\n\n    // 分类推理\n    Mat dst_cls;\n    double cof_threshold_Cls = 0.25;\n    double nms_area_threshold_Cls = 0.5;\n    vector<Object> vecObj_cls = {};\n    bool InferClsflag = yolomodel.YoloClsInfer(img_Cls, cof_threshold_Cls, nms_area_threshold_Cls, dst_cls, vecObj_cls);\n\n    // 分割推理\n    Mat dst_seg;\n    double cof_threshold_Seg = 0.25;\n    double nms_area_threshold_Seg = 0.5;\n    vector<Object> vecObj_seg = {};\n    bool InferSegflag = yolomodel.YoloSegInfer(img_Seg, cof_threshold_Seg, nms_area_threshold_Seg, dst_seg, vecObj_seg);\n\n    // 姿态推理\n    Mat dst_pose;\n    double cof_threshold_Pose = 0.25;\n    double nms_area_threshold_Pose = 0.5;\n    vector<Object> vecObj_Pose = {};\n    bool InferPoseflag = yolomodel.YoloPoseInfer(img_Pose, cof_threshold_Pose, nms_area_threshold_Pose, dst_pose, vecObj_Pose);\n\n    namedWindow("dst_pose", WINDOW_NORMAL);\n    //imshow("dst_detect", dst_detect);\n    imshow("dst_pose", dst_pose);\n    waitKey(0);\n    destroyAllWindows();\n    return 0;\n}\n\n')])]),s._v(" "),n("div",{staticClass:"line-numbers-wrapper"},[n("span",{staticClass:"line-number"},[s._v("1")]),n("br"),n("span",{staticClass:"line-number"},[s._v("2")]),n("br"),n("span",{staticClass:"line-number"},[s._v("3")]),n("br"),n("span",{staticClass:"line-number"},[s._v("4")]),n("br"),n("span",{staticClass:"line-number"},[s._v("5")]),n("br"),n("span",{staticClass:"line-number"},[s._v("6")]),n("br"),n("span",{staticClass:"line-number"},[s._v("7")]),n("br"),n("span",{staticClass:"line-number"},[s._v("8")]),n("br"),n("span",{staticClass:"line-number"},[s._v("9")]),n("br"),n("span",{staticClass:"line-number"},[s._v("10")]),n("br"),n("span",{staticClass:"line-number"},[s._v("11")]),n("br"),n("span",{staticClass:"line-number"},[s._v("12")]),n("br"),n("span",{staticClass:"line-number"},[s._v("13")]),n("br"),n("span",{staticClass:"line-number"},[s._v("14")]),n("br"),n("span",{staticClass:"line-number"},[s._v("15")]),n("br"),n("span",{staticClass:"line-number"},[s._v("16")]),n("br"),n("span",{staticClass:"line-number"},[s._v("17")]),n("br"),n("span",{staticClass:"line-number"},[s._v("18")]),n("br"),n("span",{staticClass:"line-number"},[s._v("19")]),n("br"),n("span",{staticClass:"line-number"},[s._v("20")]),n("br"),n("span",{staticClass:"line-number"},[s._v("21")]),n("br"),n("span",{staticClass:"line-number"},[s._v("22")]),n("br"),n("span",{staticClass:"line-number"},[s._v("23")]),n("br"),n("span",{staticClass:"line-number"},[s._v("24")]),n("br"),n("span",{staticClass:"line-number"},[s._v("25")]),n("br"),n("span",{staticClass:"line-number"},[s._v("26")]),n("br"),n("span",{staticClass:"line-number"},[s._v("27")]),n("br"),n("span",{staticClass:"line-number"},[s._v("28")]),n("br"),n("span",{staticClass:"line-number"},[s._v("29")]),n("br"),n("span",{staticClass:"line-number"},[s._v("30")]),n("br"),n("span",{staticClass:"line-number"},[s._v("31")]),n("br"),n("span",{staticClass:"line-number"},[s._v("32")]),n("br"),n("span",{staticClass:"line-number"},[s._v("33")]),n("br"),n("span",{staticClass:"line-number"},[s._v("34")]),n("br"),n("span",{staticClass:"line-number"},[s._v("35")]),n("br"),n("span",{staticClass:"line-number"},[s._v("36")]),n("br"),n("span",{staticClass:"line-number"},[s._v("37")]),n("br"),n("span",{staticClass:"line-number"},[s._v("38")]),n("br"),n("span",{staticClass:"line-number"},[s._v("39")]),n("br"),n("span",{staticClass:"line-number"},[s._v("40")]),n("br"),n("span",{staticClass:"line-number"},[s._v("41")]),n("br"),n("span",{staticClass:"line-number"},[s._v("42")]),n("br"),n("span",{staticClass:"line-number"},[s._v("43")]),n("br"),n("span",{staticClass:"line-number"},[s._v("44")]),n("br"),n("span",{staticClass:"line-number"},[s._v("45")]),n("br"),n("span",{staticClass:"line-number"},[s._v("46")]),n("br"),n("span",{staticClass:"line-number"},[s._v("47")]),n("br"),n("span",{staticClass:"line-number"},[s._v("48")]),n("br"),n("span",{staticClass:"line-number"},[s._v("49")]),n("br"),n("span",{staticClass:"line-number"},[s._v("50")]),n("br"),n("span",{staticClass:"line-number"},[s._v("51")]),n("br"),n("span",{staticClass:"line-number"},[s._v("52")]),n("br"),n("span",{staticClass:"line-number"},[s._v("53")]),n("br"),n("span",{staticClass:"line-number"},[s._v("54")]),n("br"),n("span",{staticClass:"line-number"},[s._v("55")]),n("br"),n("span",{staticClass:"line-number"},[s._v("56")]),n("br"),n("span",{staticClass:"line-number"},[s._v("57")]),n("br"),n("span",{staticClass:"line-number"},[s._v("58")]),n("br"),n("span",{staticClass:"line-number"},[s._v("59")]),n("br"),n("span",{staticClass:"line-number"},[s._v("60")]),n("br"),n("span",{staticClass:"line-number"},[s._v("61")]),n("br"),n("span",{staticClass:"line-number"},[s._v("62")]),n("br"),n("span",{staticClass:"line-number"},[s._v("63")]),n("br"),n("span",{staticClass:"line-number"},[s._v("64")]),n("br"),n("span",{staticClass:"line-number"},[s._v("65")]),n("br"),n("span",{staticClass:"line-number"},[s._v("66")]),n("br"),n("span",{staticClass:"line-number"},[s._v("67")]),n("br"),n("span",{staticClass:"line-number"},[s._v("68")]),n("br"),n("span",{staticClass:"line-number"},[s._v("69")]),n("br"),n("span",{staticClass:"line-number"},[s._v("70")]),n("br"),n("span",{staticClass:"line-number"},[s._v("71")]),n("br"),n("span",{staticClass:"line-number"},[s._v("72")]),n("br"),n("span",{staticClass:"line-number"},[s._v("73")]),n("br"),n("span",{staticClass:"line-number"},[s._v("74")]),n("br")])]),n("h2",{attrs:{id:"_3-完整工程"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#_3-完整工程"}},[s._v("#")]),s._v(" 3. 完整工程")]),s._v(" "),n("p",[n("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//download.csdn.net/download/qq_44747572/88580524",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://download.csdn.net/download/qq_44747572/88580524"),n("OutboundLink")],1)]),s._v(" "),n("p",[s._v("本文来自本人CSDN博客："),n("a",{attrs:{href:"https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_44747572/article/details/134309299%3Fspm%3D1001.2014.3001.5502",target:"_blank",rel:"noopener noreferrer"}},[s._v("【模型c++部署】yolov8（检测、分类、分割、姿态）使用openvino进行部署-CSDN博客"),n("OutboundLink")],1)]),s._v(" "),n("p",[s._v("本文转自 "),n("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/670618199",target:"_blank",rel:"noopener noreferrer"}},[s._v("https://zhuanlan.zhihu.com/p/670618199"),n("OutboundLink")],1),s._v("，如有侵权，请联系删除。")])])}),[],!1,null,null,null);n.default=a.exports}}]);